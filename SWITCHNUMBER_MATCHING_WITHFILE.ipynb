{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c6e7da",
   "metadata": {},
   "source": [
    "MATCHING ENERGY AUDIT VS FROM SWITCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/AFINAL.csv...\n",
      "  - Found 13868 unique, clean values.\n",
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/2-Year-data/ENERGYAUDIT.csv...\n",
      "  - Found 9954 unique, clean values.\n",
      "\n",
      "--- Comparison Report ---\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/AFINAL.csv' (Column: FROM_SWITCH): 13868\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/2-Year-data/ENERGYAUDIT.csv' (Column: SWITCH_NO): 9954\n",
      "-------------------------\n",
      "Number of values that matched: 6355\n",
      "-------------------------\n",
      "Success! Matching values have been saved to: matching_values.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148916/560392608.py:50: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION: PLEASE EDIT THIS SECTION ---\n",
    "\n",
    "# File 1 Details\n",
    "file1_path = \"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/AFINAL.csv\"\n",
    "file1_column_name = \"FROM_SWITCH\" \n",
    "# This file processed correctly before, so 'utf-8' is likely correct.\n",
    "file1_encoding = 'utf-8'  # <--- ADDED\n",
    "\n",
    "# File 2 Details\n",
    "file2_path = \"/media/sagark24/New Volume/MERGE CDIS/2-Year-data/ENERGYAUDIT.csv\"\n",
    "file2_column_name = \"SWITCH_NO\"\n",
    "# This is the file that had an error. 'latin1' is a safe choice.\n",
    "file2_encoding = 'utf-8' # <--- ADDED ('windows-1252' is also a good option)\n",
    "\n",
    "# Output File Path\n",
    "# This file will contain only the values that exist in BOTH files.\n",
    "# Changed to a simpler path. It will save in the same directory you run the script.\n",
    "output_file_path = \"matching_values.csv\" # <--- CHANGED for simplicity\n",
    "\n",
    "\n",
    "# --- END OF CONFIGURATION ---\n",
    "\n",
    "\n",
    "def find_actual_column_name(columns, target_name):\n",
    "    \"\"\"Helper function to find a column name, ignoring case.\"\"\"\n",
    "    for col in columns:\n",
    "        if str(col).lower() == str(target_name).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def get_unique_values_from_file(filepath, column_name, encoding): # <--- CHANGED (added encoding)\n",
    "    \"\"\"\n",
    "    Reads a file with a specific encoding, extracts unique values from a\n",
    "    column, cleans them, and returns them as a set.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}...\")\n",
    "    try:\n",
    "        # Read just the header to find the correct column name (case-insensitive)\n",
    "        # Pass the encoding parameter here\n",
    "        header_df = pd.read_csv(filepath, nrows=0, on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "        actual_col_name = find_actual_column_name(header_df.columns, column_name)\n",
    "\n",
    "        if not actual_col_name:\n",
    "            print(f\"  - Error: Column '{column_name}' not found. Please check the column name.\")\n",
    "            return set()\n",
    "\n",
    "        # Read the full column using the correct name and encoding\n",
    "        df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "\n",
    "        # --- Data Cleaning ---\n",
    "        # Convert all values to string, extract digits, and then convert to numbers.\n",
    "        # This handles mixed data types (e.g., '123' vs 123) and text prefixes (e.g., 'SW-123').\n",
    "        s = pd.Series(df[actual_col_name].dropna().unique(), dtype=str)\n",
    "        s = s.str.extract('(\\d+)').iloc[:, 0]\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "        cleaned_values = set(s.dropna().astype(int))\n",
    "\n",
    "        print(f\"  - Found {len(cleaned_values)} unique, clean values.\")\n",
    "        return cleaned_values\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - Error: File not found. Please check the path: {filepath}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"  - An unexpected error occurred: {e}\")\n",
    "        return set()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Get the unique values from both files, passing the encoding for each\n",
    "unique_values_from_file1 = get_unique_values_from_file(file1_path, file1_column_name, file1_encoding) # <--- CHANGED\n",
    "unique_values_from_file2 = get_unique_values_from_file(file2_path, file2_column_name, file2_encoding) # <--- CHANGED\n",
    "\n",
    "# --- Comparison and Reporting ---\n",
    "\n",
    "print(\"\\n--- Comparison Report ---\")\n",
    "if not unique_values_from_file1 or not unique_values_from_file2:\n",
    "    print(\"Could not perform comparison because one of the files could not be processed or contained no valid data.\")\n",
    "else:\n",
    "    # Use set intersection to find the values that exist in both sets\n",
    "    matching_values = unique_values_from_file1.intersection(unique_values_from_file2)\n",
    "\n",
    "    # Print the final report\n",
    "    print(f\"Unique values in '{file1_path}' (Column: {file1_column_name}): {len(unique_values_from_file1)}\")\n",
    "    print(f\"Unique values in '{file2_path}' (Column: {file2_column_name}): {len(unique_values_from_file2)}\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Number of values that matched: {len(matching_values)}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    # --- Save the results to the output file --- # <--- ADDED SECTION\n",
    "    if matching_values:\n",
    "        # Convert the set of matching values to a DataFrame\n",
    "        matching_df = pd.DataFrame(sorted(list(matching_values)), columns=['Matching_Switch_Numbers'])\n",
    "        # Save the DataFrame to a CSV file\n",
    "      \n",
    "        print(f\"Success! Matching values have been saved to: {output_file_path}\")\n",
    "    else:\n",
    "        print(\"No matching values were found to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5123d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv...\n",
      "  - Found 13663 unique, clean values.\n",
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/2-Year-data/NETWORKDETAILS.csv...\n",
      "  - Found 15423 unique, clean values.\n",
      "\n",
      "--- Comparison Report ---\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv' (Column: FROM_SWITCH): 13663\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/2-Year-data/NETWORKDETAILS.csv' (Column: FROM_SWITCHID): 15423\n",
      "-------------------------\n",
      "Number of values that matched: 8030\n",
      "-------------------------\n",
      "Success! Matching values have been saved to: matching_values.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148916/3099786136.py:50: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION: PLEASE EDIT THIS SECTION ---\n",
    "\n",
    "# File 1 Details\n",
    "file1_path = \"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv\"\n",
    "file1_column_name = \"FROM_SWITCH\" \n",
    "# This file processed correctly before, so 'utf-8' is likely correct.\n",
    "file1_encoding = 'utf-8'  # <--- ADDED\n",
    "\n",
    "# File 2 Details\n",
    "file2_path = \"/media/sagark24/New Volume/MERGE CDIS/2-Year-data/NETWORKDETAILS.csv\"\n",
    "file2_column_name = \"FROM_SWITCHID\"\n",
    "# This is the file that had an error. 'latin1' is a safe choice.\n",
    "file2_encoding = 'utf-8' # <--- ADDED ('windows-1252' is also a good option)\n",
    "\n",
    "# Output File Path\n",
    "# This file will contain only the values that exist in BOTH files.\n",
    "# Changed to a simpler path. It will save in the same directory you run the script.\n",
    "output_file_path = \"matching_values.csv\" # <--- CHANGED for simplicity\n",
    "\n",
    "\n",
    "# --- END OF CONFIGURATION ---\n",
    "\n",
    "\n",
    "def find_actual_column_name(columns, target_name):\n",
    "    \"\"\"Helper function to find a column name, ignoring case.\"\"\"\n",
    "    for col in columns:\n",
    "        if str(col).lower() == str(target_name).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def get_unique_values_from_file(filepath, column_name, encoding): # <--- CHANGED (added encoding)\n",
    "    \"\"\"\n",
    "    Reads a file with a specific encoding, extracts unique values from a\n",
    "    column, cleans them, and returns them as a set.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}...\")\n",
    "    try:\n",
    "        # Read just the header to find the correct column name (case-insensitive)\n",
    "        # Pass the encoding parameter here\n",
    "        header_df = pd.read_csv(filepath, nrows=0, on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "        actual_col_name = find_actual_column_name(header_df.columns, column_name)\n",
    "\n",
    "        if not actual_col_name:\n",
    "            print(f\"  - Error: Column '{column_name}' not found. Please check the column name.\")\n",
    "            return set()\n",
    "\n",
    "        # Read the full column using the correct name and encoding\n",
    "        df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "\n",
    "        # --- Data Cleaning ---\n",
    "        # Convert all values to string, extract digits, and then convert to numbers.\n",
    "        # This handles mixed data types (e.g., '123' vs 123) and text prefixes (e.g., 'SW-123').\n",
    "        s = pd.Series(df[actual_col_name].dropna().unique(), dtype=str)\n",
    "        s = s.str.extract('(\\d+)').iloc[:, 0]\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "        cleaned_values = set(s.dropna().astype(int))\n",
    "\n",
    "        print(f\"  - Found {len(cleaned_values)} unique, clean values.\")\n",
    "        return cleaned_values\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - Error: File not found. Please check the path: {filepath}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"  - An unexpected error occurred: {e}\")\n",
    "        return set()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Get the unique values from both files, passing the encoding for each\n",
    "unique_values_from_file1 = get_unique_values_from_file(file1_path, file1_column_name, file1_encoding) # <--- CHANGED\n",
    "unique_values_from_file2 = get_unique_values_from_file(file2_path, file2_column_name, file2_encoding) # <--- CHANGED\n",
    "\n",
    "# --- Comparison and Reporting ---\n",
    "\n",
    "print(\"\\n--- Comparison Report ---\")\n",
    "if not unique_values_from_file1 or not unique_values_from_file2:\n",
    "    print(\"Could not perform comparison because one of the files could not be processed or contained no valid data.\")\n",
    "else:\n",
    "    # Use set intersection to find the values that exist in both sets\n",
    "    matching_values = unique_values_from_file1.intersection(unique_values_from_file2)\n",
    "\n",
    "    # Print the final report\n",
    "    print(f\"Unique values in '{file1_path}' (Column: {file1_column_name}): {len(unique_values_from_file1)}\")\n",
    "    print(f\"Unique values in '{file2_path}' (Column: {file2_column_name}): {len(unique_values_from_file2)}\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Number of values that matched: {len(matching_values)}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    # --- Save the results to the output file --- # <--- ADDED SECTION\n",
    "    if matching_values:\n",
    "        # Convert the set of matching values to a DataFrame\n",
    "        matching_df = pd.DataFrame(sorted(list(matching_values)), columns=['Matching_Switch_Numbers'])\n",
    "        # Save the DataFrame to a CSV file\n",
    "      \n",
    "        print(f\"Success! Matching values have been saved to: {output_file_path}\")\n",
    "    else:\n",
    "        print(\"No matching values were found to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv...\n",
      "  - Found 63 unique, clean values.\n",
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/2-Year-data/NETWORKDETAILS.csv...\n",
      "  - Found 74 unique, clean values.\n",
      "\n",
      "--- Comparison Report ---\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv' (Column: SOURCE_SS): 63\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/2-Year-data/NETWORKDETAILS.csv' (Column: FROM_STN): 74\n",
      "-------------------------\n",
      "Number of values that matched: 60\n",
      "-------------------------\n",
      "Success! Matching values have been saved to: matching_values.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION: PLEASE EDIT THIS SECTION ---\n",
    "\n",
    "# File 1 Details\n",
    "file1_path = \"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv\"\n",
    "file1_column_name = \"SOURCE_SS\" \n",
    "# This file processed correctly before, so 'utf-8' is likely correct.\n",
    "file1_encoding = 'utf-8'  # <--- ADDED\n",
    "\n",
    "# File 2 Details\n",
    "file2_path = \"/media/sagark24/New Volume/MERGE CDIS/2-Year-data/NETWORKDETAILS.csv\"\n",
    "file2_column_name = \"FROM_STN\"\n",
    "# This is the file that had an error. 'latin1' is a safe choice.\n",
    "file2_encoding = 'utf-8' # <--- ADDED ('windows-1252' is also a good option)\n",
    "\n",
    "# Output File Path\n",
    "# This file will contain only the values that exist in BOTH files.\n",
    "# Changed to a simpler path. It will save in the same directory you run the script.\n",
    "output_file_path = \"matching_values.csv\" # <--- CHANGED for simplicity\n",
    "\n",
    "\n",
    "# --- END OF CONFIGURATION ---\n",
    "\n",
    "\n",
    "def find_actual_column_name(columns, target_name):\n",
    "    \"\"\"Helper function to find a column name, ignoring case.\"\"\"\n",
    "    for col in columns:\n",
    "        if str(col).lower() == str(target_name).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def get_unique_values_from_file(filepath, column_name, encoding): # <--- CHANGED (added encoding)\n",
    "    \"\"\"\n",
    "    Reads a file with a specific encoding, extracts unique values from a\n",
    "    column, cleans them, and returns them as a set.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}...\")\n",
    "    try:\n",
    "        # Read just the header to find the correct column name (case-insensitive)\n",
    "        # Pass the encoding parameter here\n",
    "        header_df = pd.read_csv(filepath, nrows=0, on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "        actual_col_name = find_actual_column_name(header_df.columns, column_name)\n",
    "\n",
    "        if not actual_col_name:\n",
    "            print(f\"  - Error: Column '{column_name}' not found. Please check the column name.\")\n",
    "            return set()\n",
    "\n",
    "        # Read the full column using the correct name and encoding\n",
    "        df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "\n",
    "        # --- Data Cleaning ---\n",
    "        # Convert all values to string, extract digits, and then convert to numbers.\n",
    "        # This handles mixed data types (e.g., '123' vs 123) and text prefixes (e.g., 'SW-123').\n",
    "        s = pd.Series(df[actual_col_name].dropna().unique(), dtype=str)\n",
    "        s = s.str.extract('(\\d+)').iloc[:, 0]\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "        cleaned_values = set(s.dropna().astype(int))\n",
    "\n",
    "        print(f\"  - Found {len(cleaned_values)} unique, clean values.\")\n",
    "        return cleaned_values\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - Error: File not found. Please check the path: {filepath}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"  - An unexpected error occurred: {e}\")\n",
    "        return set()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Get the unique values from both files, passing the encoding for each\n",
    "unique_values_from_file1 = get_unique_values_from_file(file1_path, file1_column_name, file1_encoding) # <--- CHANGED\n",
    "unique_values_from_file2 = get_unique_values_from_file(file2_path, file2_column_name, file2_encoding) # <--- CHANGED\n",
    "\n",
    "# --- Comparison and Reporting ---\n",
    "\n",
    "print(\"\\n--- Comparison Report ---\")\n",
    "if not unique_values_from_file1 or not unique_values_from_file2:\n",
    "    print(\"Could not perform comparison because one of the files could not be processed or contained no valid data.\")\n",
    "else:\n",
    "    # Use set intersection to find the values that exist in both sets\n",
    "    matching_values = unique_values_from_file1.intersection(unique_values_from_file2)\n",
    "\n",
    "    # Print the final report\n",
    "    print(f\"Unique values in '{file1_path}' (Column: {file1_column_name}): {len(unique_values_from_file1)}\")\n",
    "    print(f\"Unique values in '{file2_path}' (Column: {file2_column_name}): {len(unique_values_from_file2)}\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Number of values that matched: {len(matching_values)}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    # --- Save the results to the output file --- # <--- ADDED SECTION\n",
    "    if matching_values:\n",
    "        # Convert the set of matching values to a DataFrame\n",
    "        matching_df = pd.DataFrame(sorted(list(matching_values)), columns=['Matching_Switch_Numbers'])\n",
    "        # Save the DataFrame to a CSV file\n",
    "      \n",
    "        print(f\"Success! Matching values have been saved to: {output_file_path}\")\n",
    "    else:\n",
    "        print(\"No matching values were found to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3b216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be3ae0d0",
   "metadata": {},
   "source": [
    "FAULT DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d4fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv...\n",
      "  - Found 1199 unique, clean values.\n",
      "Processing file: /media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/HT_fault_cable_info_processed2.csv...\n",
      "  - Found 1263 unique, clean values.\n",
      "\n",
      "--- Comparison Report ---\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv' (Column: FEEDER_ID): 1199\n",
      "Unique values in '/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/HT_fault_cable_info_processed2.csv' (Column: SWITCH_NO): 1263\n",
      "-------------------------\n",
      "Number of values that matched: 826\n",
      "-------------------------\n",
      "Success! Matching values have been saved to: matching_values.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION: PLEASE EDIT THIS SECTION ---\n",
    "\n",
    "# File 1 Details\n",
    "file1_path = \"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/11_KV_FINAL_HEALTH/AFINAL_full.csv\"\n",
    "file1_column_name = \"FEEDER_ID\" \n",
    "# This file processed correctly before, so 'utf-8' is likely correct.\n",
    "file1_encoding = 'utf-8'  # <--- ADDED\n",
    "\n",
    "# File 2 Details\n",
    "file2_path = \"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/HT_fault_cable_info_processed2.csv\"\n",
    "file2_column_name = \"SWITCH_NO\"\n",
    "# This is the file that had an error. 'latin1' is a safe choice.\n",
    "file2_encoding = 'utf-8' # <--- ADDED ('windows-1252' is also a good option)\n",
    "\n",
    "# Output File Path\n",
    "# This file will contain only the values that exist in BOTH files.\n",
    "# Changed to a simpler path. It will save in the same directory you run the script.\n",
    "output_file_path = \"matching_values.csv\" # <--- CHANGED for simplicity\n",
    "\n",
    "\n",
    "# --- END OF CONFIGURATION ---\n",
    "\n",
    "\n",
    "def find_actual_column_name(columns, target_name):\n",
    "    \"\"\"Helper function to find a column name, ignoring case.\"\"\"\n",
    "    for col in columns:\n",
    "        if str(col).lower() == str(target_name).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def get_unique_values_from_file(filepath, column_name, encoding): # <--- CHANGED (added encoding)\n",
    "    \"\"\"\n",
    "    Reads a file with a specific encoding, extracts unique values from a\n",
    "    column, cleans them, and returns them as a set.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}...\")\n",
    "    try:\n",
    "        # Read just the header to find the correct column name (case-insensitive)\n",
    "        # Pass the encoding parameter here\n",
    "        header_df = pd.read_csv(filepath, nrows=0, on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "        actual_col_name = find_actual_column_name(header_df.columns, column_name)\n",
    "\n",
    "        if not actual_col_name:\n",
    "            print(f\"  - Error: Column '{column_name}' not found. Please check the column name.\")\n",
    "            return set()\n",
    "\n",
    "        # Read the full column using the correct name and encoding\n",
    "        df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip', encoding=encoding) # <--- CHANGED\n",
    "\n",
    "        # --- Data Cleaning ---\n",
    "        # Convert all values to string, extract digits, and then convert to numbers.\n",
    "        # This handles mixed data types (e.g., '123' vs 123) and text prefixes (e.g., 'SW-123').\n",
    "        s = pd.Series(df[actual_col_name].dropna().unique(), dtype=str)\n",
    "        # s = s.str.extract('(\\d+)').iloc[:, 0]\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "        cleaned_values = set(s.dropna().astype(int))\n",
    "\n",
    "        print(f\"  - Found {len(cleaned_values)} unique, clean values.\")\n",
    "        return cleaned_values\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - Error: File not found. Please check the path: {filepath}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"  - An unexpected error occurred: {e}\")\n",
    "        return set()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Get the unique values from both files, passing the encoding for each\n",
    "unique_values_from_file1 = get_unique_values_from_file(file1_path, file1_column_name, file1_encoding) # <--- CHANGED\n",
    "unique_values_from_file2 = get_unique_values_from_file(file2_path, file2_column_name, file2_encoding) # <--- CHANGED\n",
    "\n",
    "# --- Comparison and Reporting ---\n",
    "\n",
    "print(\"\\n--- Comparison Report ---\")\n",
    "if not unique_values_from_file1 or not unique_values_from_file2:\n",
    "    print(\"Could not perform comparison because one of the files could not be processed or contained no valid data.\")\n",
    "else:\n",
    "    # Use set intersection to find the values that exist in both sets\n",
    "    matching_values = unique_values_from_file1.intersection(unique_values_from_file2)\n",
    "\n",
    "    # Print the final report\n",
    "    print(f\"Unique values in '{file1_path}' (Column: {file1_column_name}): {len(unique_values_from_file1)}\")\n",
    "    print(f\"Unique values in '{file2_path}' (Column: {file2_column_name}): {len(unique_values_from_file2)}\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Number of values that matched: {len(matching_values)}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    # --- Save the results to the output file --- # <--- ADDED SECTION\n",
    "    if matching_values:\n",
    "        # Convert the set of matching values to a DataFrame\n",
    "        matching_df = pd.DataFrame(sorted(list(matching_values)), columns=['Matching_Switch_Numbers'])\n",
    "        # Save the DataFrame to a CSV file\n",
    "      \n",
    "        print(f\"Success! Matching values have been saved to: {output_file_path}\")\n",
    "    else:\n",
    "        print(\"No matching values were found to save.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
