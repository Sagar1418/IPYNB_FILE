{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf450e02",
   "metadata": {},
   "source": [
    "SAMPLE OUTPUT OF 100 LINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15057ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/1705334388.py:18: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n",
      "/tmp/ipykernel_2374358/1705334388.py:19: DtypeWarning: Columns (1,2,13,14,15,17,28,30,43,44,58,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  htcable = pd.read_csv(\"HTCABLE.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved first 100 rows to scada_htcable_chain.xlsx \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define folder path where SCADA .csv is stored\n",
    "folder_path = \"2-Year-data/200/200\"\n",
    "\n",
    "# Automatically fetch the SCADA CSV file\n",
    "scada_file = None\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.lower().endswith(\".csv\"):\n",
    "        scada_file = os.path.join(folder_path, file)\n",
    "        break\n",
    "\n",
    "if scada_file is None:\n",
    "    raise FileNotFoundError(\"No SCADA .csv file found in the folder!\")\n",
    "\n",
    "# Load SCADA and HT cable files\n",
    "scada = pd.read_csv(scada_file)\n",
    "htcable = pd.read_csv(\"HTCABLE.csv\")\n",
    "\n",
    "# Filter SCADA by voltage containing \"11\"\n",
    "scada_filtered = scada[scada['VOLTAGE'].astype(str).str.contains(\"11\", case=False)]\n",
    "\n",
    "# Create a DataFrame for results\n",
    "columns = ['SOURCE_SWITCH_ID', 'DESTINATION_SWITCH_ID', 'SOURCE_SSFL', 'DESTINATION_SSFL']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Track processed switches and total rows added\n",
    "processed_switches = set()\n",
    "row_limit = 200\n",
    "\n",
    "# Traverse each Swno\n",
    "for swno in scada_filtered['SWNO'].unique():\n",
    "    if swno in processed_switches or len(results) >= row_limit:\n",
    "        break\n",
    "\n",
    "    current_from_switch = swno\n",
    "    first_match = htcable[htcable['SOURCE_SWITCH_ID'] == current_from_switch]\n",
    "\n",
    "    if first_match.empty:\n",
    "        continue\n",
    "\n",
    "    for _, row in first_match.iterrows():\n",
    "        temp_chain = []\n",
    "\n",
    "        source = row['SOURCE_SSFL']\n",
    "        dest = row['DESTINATION_SSFL']\n",
    "        to_switch = row['DESTINATION_SWITCH_ID'] if 'DESTINATION_SWITCH_ID' in row else None\n",
    "        temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "        processed_switches.add(current_from_switch)\n",
    "\n",
    "        # Continue chain traversal\n",
    "    visited_ssfl = set()  # Add this before the while loop\n",
    "\n",
    "    # Inside the loop:\n",
    "  # Inside the loop:\n",
    "    visited_ssfl = set()\n",
    "\n",
    "    while len(results) + len(temp_chain) < row_limit:\n",
    "        next_match = htcable[htcable['SOURCE_SSFL'] == dest]\n",
    "\n",
    "        if next_match.empty or dest in visited_ssfl:\n",
    "            break\n",
    "\n",
    "        next_row = next_match.iloc[0]\n",
    "        source = next_row['SOURCE_SSFL']\n",
    "        dest = next_row['DESTINATION_SSFL']\n",
    "\n",
    "        #  Prevent self-loop\n",
    "        if source == dest:\n",
    "            break\n",
    "\n",
    "        visited_ssfl.add(source)\n",
    "\n",
    "        current_from_switch = next_row['SOURCE_SWITCH_ID']\n",
    "        to_switch = next_row['DESTINATION_SWITCH_ID'] if 'DESTINATION_SWITCH_ID' in next_row else None\n",
    "\n",
    "        temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "        processed_switches.add(current_from_switch)\n",
    "\n",
    "        # Append chain, checking if limit exceeded\n",
    "        for item in temp_chain:\n",
    "            if len(results) >= row_limit:\n",
    "                break\n",
    "            results.loc[len(results)] = item\n",
    "\n",
    "        if len(results) >= row_limit:\n",
    "            break\n",
    "\n",
    "# Save results\n",
    "results.to_excel(\"scada_htcable_chain.xlsx\", index=False)\n",
    "print(\"Saved first 100 rows to scada_htcable_chain.xlsx \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9ff7e",
   "metadata": {},
   "source": [
    "IT FILTERS THE SCADA DATA BY VOLTAGE AND FULL SCADA DATA LOADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca398d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:13: DtypeWarning: Columns (1,2,13,14,15,17,28,30,43,44,58,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  htcable = pd.read_csv(\"HTCABLE.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Processing folder: 2-Year-data/200/200\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000182.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000183.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000184.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000185.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000186.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000187.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000188.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000189.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000190.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000191.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000192.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000193.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000194.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000195.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000196.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000197.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000198.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000199.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/700301337.py:32: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000000.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000001.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000002.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000003.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000004.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000005.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000006.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000007.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000008.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000009.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000010.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000011.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000013.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000014.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000015.csv\n",
      "   ðŸ” Processing SCADA file: 2025-05-07_SCADA000000000016.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     51\u001b[0m current_from_switch \u001b[38;5;241m=\u001b[39m swno\n\u001b[0;32m---> 52\u001b[0m first_match \u001b[38;5;241m=\u001b[39m htcable[\u001b[43mhtcable\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSOURCE_SWITCH_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurrent_from_switch\u001b[49m]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_match\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32mops.pyx:95\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List all SCADA folders you want to process\n",
    "target_folders = [\n",
    "    \"2-Year-data/200/200\",\n",
    "    \"2-Year-data/200-400/200-400\",\n",
    "    \"2-Year-data/400-600/400-600\",\n",
    "    \"2-Year-data/600-759/600-759\"\n",
    "]\n",
    "\n",
    "# Load HT cable file once\n",
    "htcable = pd.read_csv(\"HTCABLE.csv\")\n",
    "\n",
    "# Prepare final results DataFrame with updated column names\n",
    "columns = ['SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID', 'SOURCE_SSFL', 'DESTINATION_SSFL', 'SFL']\n",
    "final_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Process each SCADA folder\n",
    "for folder_path in target_folders:\n",
    "    print(f\" Processing folder: {folder_path}\")\n",
    "\n",
    "    # Loop through all SCADA CSV files in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue  # Skip non-CSV files\n",
    "\n",
    "        scada_file = os.path.join(folder_path, file)\n",
    "        print(f\"   Processing SCADA file: {file}\")\n",
    "        \n",
    "        try:\n",
    "            scada = pd.read_csv(scada_file)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error reading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if 'VOLTAGE' not in scada.columns or 'SWNO' not in scada.columns:\n",
    "            print(f\"    Missing required columns in {file}\")\n",
    "            continue\n",
    "\n",
    "        # Filter SCADA by voltage containing \"11\"\n",
    "        scada_filtered = scada[scada['VOLTAGE'].astype(str).str.contains(\"11\", case=False)]\n",
    "\n",
    "        processed_switches = set()\n",
    "\n",
    "        # Traverse each Swno\n",
    "        for swno in scada_filtered['SWNO'].unique():\n",
    "            if swno in processed_switches:\n",
    "                continue\n",
    "\n",
    "            current_from_switch = swno\n",
    "            first_match = htcable[htcable['SOURCE_SWITCH_ID'] == current_from_switch]\n",
    "\n",
    "            if first_match.empty:\n",
    "                continue\n",
    "\n",
    "            for _, row in first_match.iterrows():\n",
    "                temp_chain = []\n",
    "\n",
    "                source = row['SOURCE_SSFL']\n",
    "                dest = row['DESTINATION_SSFL']\n",
    "                to_switch = row.get('DESTINATION_SWITCH_ID', None)\n",
    "                temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                processed_switches.add(current_from_switch)\n",
    "\n",
    "                # Begin chain traversal\n",
    "                visited_ssfl = set()\n",
    "\n",
    "                while True:\n",
    "                    next_match = htcable[htcable['SOURCE_SSFL'] == dest]\n",
    "\n",
    "                    if next_match.empty or dest in visited_ssfl:\n",
    "                        break\n",
    "\n",
    "                    next_row = next_match.iloc[0]\n",
    "                    source = next_row['SOURCE_SSFL']\n",
    "                    dest = next_row['DESTINATION_SSFL']\n",
    "\n",
    "                    if source == dest:\n",
    "                        break  # Prevent self-loop\n",
    "\n",
    "                    visited_ssfl.add(source)\n",
    "\n",
    "                    current_from_switch = next_row['SOURCE_SWITCH_ID']\n",
    "                    to_switch = next_row.get('DESTINATION_SWITCH_ID', None)\n",
    "\n",
    "                    temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                    processed_switches.add(current_from_switch)\n",
    "\n",
    "                # Add this chain to final results\n",
    "                for item in temp_chain:\n",
    "                    source_switch = item[0]\n",
    "                    dest_switch = item[1]\n",
    "                    source_ssfl = item[2]\n",
    "                    dest_ssfl = item[3]\n",
    "                    combined_id = f\"{source_switch}-{dest_switch}\"\n",
    "                    final_results.loc[len(final_results)] = [combined_id, source_ssfl, dest_ssfl, dest_ssfl]\n",
    "\n",
    "# Save combined results\n",
    "final_results.to_excel(\"scada_htcable_chain_all_folders.xlsx\", index=False)\n",
    "print(f\"\\n Done! Saved {len(final_results)} rows from all folders to scada_htcable_chain_all_folders.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665d5ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58ca6eb0",
   "metadata": {},
   "source": [
    "REMOVE THE SCADA DATA FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List all SCADA folders you want to process\n",
    "target_folders = [\n",
    "    \"2-Year-data/200/200\",\n",
    "    \"2-Year-data/200-400/200-400\",\n",
    "    \"2-Year-data/400-600/400-600\",\n",
    "    \"2-Year-data/600-759/600-759\"\n",
    "]\n",
    "\n",
    "# Load HT cable file once\n",
    "htcable = pd.read_csv(\"HTCABLE.csv\")\n",
    "\n",
    "# Prepare final results DataFrame with updated column names\n",
    "columns = ['SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID', 'SOURCE_SSFL', 'DESTINATION_SSFL', 'SFL']\n",
    "final_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Process each SCADA folder\n",
    "for folder_path in target_folders:\n",
    "    print(f\" Processing folder: {folder_path}\")\n",
    "\n",
    "    # Loop through all SCADA CSV files in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue  # Skip non-CSV files\n",
    "\n",
    "        scada_file = os.path.join(folder_path, file)\n",
    "        print(f\"    Processing SCADA file: {file}\")\n",
    "        \n",
    "        try:\n",
    "            scada = pd.read_csv(scada_file)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error reading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if 'SWNO' not in scada.columns:\n",
    "            print(f\"    Missing 'SWNO' column in {file}\")\n",
    "            continue\n",
    "\n",
    "        processed_switches = set()\n",
    "\n",
    "        # Traverse each Swno\n",
    "        for swno in scada['SWNO'].unique():\n",
    "            if swno in processed_switches:\n",
    "                continue\n",
    "\n",
    "            current_from_switch = swno\n",
    "            first_match = htcable[htcable['SOURCE_SWITCH_ID'] == current_from_switch]\n",
    "\n",
    "            if first_match.empty:\n",
    "                continue\n",
    "\n",
    "            for _, row in first_match.iterrows():\n",
    "                temp_chain = []\n",
    "\n",
    "                source = row['SOURCE_SSFL']\n",
    "                dest = row['DESTINATION_SSFL']\n",
    "                to_switch = row.get('DESTINATION_SWITCH_ID', None)\n",
    "                temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                processed_switches.add(current_from_switch)\n",
    "\n",
    "                # Begin chain traversal\n",
    "                visited_ssfl = set()\n",
    "\n",
    "                while True:\n",
    "                    next_match = htcable[htcable['SOURCE_SSFL'] == dest]\n",
    "\n",
    "                    if next_match.empty or dest in visited_ssfl:\n",
    "                        break\n",
    "\n",
    "                    next_row = next_match.iloc[0]\n",
    "                    source = next_row['SOURCE_SSFL']\n",
    "                    dest = next_row['DESTINATION_SSFL']\n",
    "\n",
    "                    if source == dest:\n",
    "                        break  # Prevent self-loop\n",
    "\n",
    "                    visited_ssfl.add(source)\n",
    "\n",
    "                    current_from_switch = next_row['SOURCE_SWITCH_ID']\n",
    "                    to_switch = next_row.get('DESTINATION_SWITCH_ID', None)\n",
    "\n",
    "                    temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                    processed_switches.add(current_from_switch)\n",
    "\n",
    "                # Add this chain to final results\n",
    "                for item in temp_chain:\n",
    "                    source_switch = item[0]\n",
    "                    dest_switch = item[1]\n",
    "                    source_ssfl = item[2]\n",
    "                    dest_ssfl = item[3]\n",
    "                    combined_id = f\"{source_switch}-{dest_switch}\"\n",
    "                    final_results.loc[len(final_results)] = [combined_id, source_ssfl, dest_ssfl, dest_ssfl]\n",
    "\n",
    "# Save combined results\n",
    "final_results.to_excel(\"scada_htcable_chain_all_folders.xlsx\", index=False)\n",
    "print(f\"\\n Done! Saved {len(final_results)} rows from all folders to scada_htcable_chain_all_folders.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68cae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95249cd5",
   "metadata": {},
   "source": [
    "CREATE UNIQUE CHAINS TO REMOVE DUPLICATES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4093a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/4244324119.py:13: DtypeWarning: Columns (1,2,13,14,15,17,28,30,43,44,58,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  htcable = pd.read_csv(\"HTCABLE.csv\").drop_duplicates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing folder: 2-Year-data/200/200\n",
      "    Processing SCADA file: 2025-05-07_SCADA000000000182.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/4244324119.py:35: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing SCADA file: 2025-05-07_SCADA000000000183.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/4244324119.py:35: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing SCADA file: 2025-05-07_SCADA000000000184.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/4244324119.py:35: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m visited_ssfl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     next_match \u001b[38;5;241m=\u001b[39m htcable[\u001b[43mhtcable\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSOURCE_SSFL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_match\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mor\u001b[39;00m dest \u001b[38;5;129;01min\u001b[39;00m visited_ssfl:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List all SCADA folders you want to process\n",
    "target_folders = [\n",
    "    \"2-Year-data/200/200\",\n",
    "    \"2-Year-data/200-400/200-400\",\n",
    "    \"2-Year-data/400-600/400-600\",\n",
    "    \"2-Year-data/600-759/600-759\"\n",
    "]\n",
    "\n",
    "# Load HT cable file once and drop any exact duplicates\n",
    "htcable = pd.read_csv(\"HTCABLE.csv\").drop_duplicates()\n",
    "\n",
    "# Prepare final results DataFrame\n",
    "columns = ['SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID', 'SOURCE_SSFL', 'DESTINATION_SSFL', 'SFL']\n",
    "final_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "# To store only unique chains (row-level uniqueness)\n",
    "unique_chains = set()\n",
    "\n",
    "# Process each SCADA folder\n",
    "for folder_path in target_folders:\n",
    "    print(f\" Processing folder: {folder_path}\")\n",
    "\n",
    "    # Loop through all SCADA CSV files in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue  # Skip non-CSV files\n",
    "\n",
    "        scada_file = os.path.join(folder_path, file)\n",
    "        print(f\"    Processing SCADA file: {file}\")\n",
    "        \n",
    "        try:\n",
    "            scada = pd.read_csv(scada_file)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error reading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if 'SWNO' not in scada.columns:\n",
    "            print(f\"    Missing 'SWNO' column in {file}\")\n",
    "            continue\n",
    "\n",
    "        processed_switches = set()\n",
    "\n",
    "        # Traverse each Swno\n",
    "        for swno in scada['SWNO'].unique():\n",
    "            if swno in processed_switches:\n",
    "                continue\n",
    "\n",
    "            current_from_switch = swno\n",
    "            first_match = htcable[htcable['SOURCE_SWITCH_ID'] == current_from_switch]\n",
    "\n",
    "            if first_match.empty:\n",
    "                continue\n",
    "\n",
    "            for _, row in first_match.iterrows():\n",
    "                temp_chain = []\n",
    "\n",
    "                source = row['SOURCE_SSFL']\n",
    "                dest = row['DESTINATION_SSFL']\n",
    "                to_switch = row.get('DESTINATION_SWITCH_ID', None)\n",
    "                temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                processed_switches.add(current_from_switch)\n",
    "\n",
    "                # Begin chain traversal\n",
    "                visited_ssfl = set()\n",
    "\n",
    "                while True:\n",
    "                    next_match = htcable[htcable['SOURCE_SSFL'] == dest]\n",
    "\n",
    "                    if next_match.empty or dest in visited_ssfl:\n",
    "                        break\n",
    "\n",
    "                    next_row = next_match.iloc[0]\n",
    "                    source = next_row['SOURCE_SSFL']\n",
    "                    dest = next_row['DESTINATION_SSFL']\n",
    "\n",
    "                    if source == dest:\n",
    "                        break  # Prevent self-loop\n",
    "\n",
    "                    visited_ssfl.add(source)\n",
    "\n",
    "                    current_from_switch = next_row['SOURCE_SWITCH_ID']\n",
    "                    to_switch = next_row.get('DESTINATION_SWITCH_ID', None)\n",
    "\n",
    "                    temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                    processed_switches.add(current_from_switch)\n",
    "\n",
    "                # Add only unique chain links to final results\n",
    "                for item in temp_chain:\n",
    "                    chain_tuple = tuple(item)\n",
    "                    if chain_tuple in unique_chains:\n",
    "                        continue  # Skip duplicate\n",
    "                    unique_chains.add(chain_tuple)\n",
    "\n",
    "                    source_switch = item[0]\n",
    "                    dest_switch = item[1]\n",
    "                    source_ssfl = item[2]\n",
    "                    dest_ssfl = item[3]\n",
    "                    combined_id = f\"{source_switch}-{dest_switch}\"\n",
    "\n",
    "                    final_results.loc[len(final_results)] = [combined_id, source_ssfl, dest_ssfl, dest_ssfl]\n",
    "\n",
    "# Save combined results\n",
    "final_results.to_excel(\"scada_htcable_chain_all_folders_deduped.xlsx\", index=False)\n",
    "print(f\"\\n Done! Saved {len(final_results)} unique rows to scada_htcable_chain_all_folders_deduped.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0913aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a54a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aaf07a8",
   "metadata": {},
   "source": [
    "SANMPLE OF ABOVE SCRIPT IN 100 LINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f3c5409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/2286576012.py:13: DtypeWarning: Columns (1,2,13,14,15,17,28,30,43,44,58,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  htcable = pd.read_csv(\"HTCABLE.csv\").drop_duplicates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 2-Year-data/200/200\n",
      "    Processing SCADA file: 2025-05-07_SCADA000000000182.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2374358/2286576012.py:43: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  scada = pd.read_csv(scada_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done! Saved 201 rows to scada_htcable_chain_200_rows.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List all SCADA folders you want to process\n",
    "target_folders = [\n",
    "    \"2-Year-data/200/200\",\n",
    "    \"2-Year-data/200-400/200-400\",\n",
    "    \"2-Year-data/400-600/400-600\",\n",
    "    \"2-Year-data/600-759/600-759\"\n",
    "]\n",
    "\n",
    "# Load HT cable file once and drop any exact duplicates\n",
    "htcable = pd.read_csv(\"HTCABLE.csv\").drop_duplicates()\n",
    "\n",
    "# Prepare final results DataFrame\n",
    "columns = ['SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID', 'SOURCE_SSFL', 'DESTINATION_SSFL', 'SFL']\n",
    "final_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Track unique chain links\n",
    "unique_chains = set()\n",
    "\n",
    "# Row limit\n",
    "ROW_LIMIT = 200\n",
    "\n",
    "# Flag to exit outer loops\n",
    "done = False\n",
    "\n",
    "for folder_path in target_folders:\n",
    "    if done:\n",
    "        break\n",
    "    print(f\"Processing folder: {folder_path}\")\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if done:\n",
    "            break\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        scada_file = os.path.join(folder_path, file)\n",
    "        print(f\"    Processing SCADA file: {file}\")\n",
    "\n",
    "        try:\n",
    "            scada = pd.read_csv(scada_file)\n",
    "        except Exception as e:\n",
    "            print(f\"   Error reading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if 'SWNO' not in scada.columns:\n",
    "            print(f\"   Missing 'SWNO' column in {file}\")\n",
    "            continue\n",
    "\n",
    "        processed_switches = set()\n",
    "\n",
    "        for swno in scada['SWNO'].unique():\n",
    "            if done:\n",
    "                break\n",
    "            if swno in processed_switches:\n",
    "                continue\n",
    "\n",
    "            current_from_switch = swno\n",
    "            first_match = htcable[htcable['SOURCE_SWITCH_ID'] == current_from_switch]\n",
    "\n",
    "            if first_match.empty:\n",
    "                continue\n",
    "\n",
    "            for _, row in first_match.iterrows():\n",
    "                temp_chain = []\n",
    "\n",
    "                source = row['SOURCE_SSFL']\n",
    "                dest = row['DESTINATION_SSFL']\n",
    "                to_switch = row.get('DESTINATION_SWITCH_ID', None)\n",
    "                temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                processed_switches.add(current_from_switch)\n",
    "\n",
    "                visited_ssfl = set()\n",
    "\n",
    "                while True:\n",
    "                    next_match = htcable[htcable['SOURCE_SSFL'] == dest]\n",
    "\n",
    "                    if next_match.empty or dest in visited_ssfl:\n",
    "                        break\n",
    "\n",
    "                    next_row = next_match.iloc[0]\n",
    "                    source = next_row['SOURCE_SSFL']\n",
    "                    dest = next_row['DESTINATION_SSFL']\n",
    "\n",
    "                    if source == dest:\n",
    "                        break\n",
    "\n",
    "                    visited_ssfl.add(source)\n",
    "\n",
    "                    current_from_switch = next_row['SOURCE_SWITCH_ID']\n",
    "                    to_switch = next_row.get('DESTINATION_SWITCH_ID', None)\n",
    "                    temp_chain.append([current_from_switch, to_switch, source, dest])\n",
    "                    processed_switches.add(current_from_switch)\n",
    "\n",
    "                # Add unique items to result\n",
    "                for item in temp_chain:\n",
    "                    chain_tuple = tuple(item)\n",
    "                    if chain_tuple in unique_chains:\n",
    "                        continue\n",
    "\n",
    "                    unique_chains.add(chain_tuple)\n",
    "                    source_switch = item[0]\n",
    "                    dest_switch = item[1]\n",
    "                    source_ssfl = item[2]\n",
    "                    dest_ssfl = item[3]\n",
    "                    combined_id = f\"{source_switch}-{dest_switch}\"\n",
    "\n",
    "                    final_results.loc[len(final_results)] = [combined_id, source_ssfl, dest_ssfl, dest_ssfl]\n",
    "\n",
    "                    # Stop after 200 rows\n",
    "                    if len(final_results) >= ROW_LIMIT:\n",
    "                        done = True\n",
    "                        break\n",
    "\n",
    "# Save the limited results\n",
    "final_results.to_excel(\"scada_htcable_chain_200_rows.xlsx\", index=False)\n",
    "print(f\"\\n Done! Saved {len(final_results)} rows to scada_htcable_chain_200_rows.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df858537",
   "metadata": {},
   "source": [
    "NEW LOGIC HANDLE THE MULTOLE SAME ROWS THA ARE IN THE HTCABLE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1579f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# 1.  PRE-PROCESS THE HT-CABLE FILE\n",
    "\n",
    "cols_to_drop = [\"COMMENTS\", \"GLOBALID\", \"MEASUREDLENGTH\",\n",
    "                \"Unnamed: 0\", \"OBJECTID\"]\n",
    "\n",
    "htcable = (\n",
    "    pd.read_csv(\"HTCABLE.csv\", low_memory=False)\n",
    "      .drop(columns=cols_to_drop, errors=\"ignore\")            # throw away noisy cols\n",
    "      .drop_duplicates(subset=[\"SOURCE_SWITCH_ID\",\n",
    "                               \"DESTINATION_SWITCH_ID\",\n",
    "                               \"SOURCE_SSFL\",\n",
    "                               \"DESTINATION_SSFL\"])           # keep only unique edges\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "# 2.  PREPARE OUTPUT CONTAINER\n",
    "\n",
    "out_cols = [\"SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID\",\n",
    "            \"SOURCE_SSFL\", \"DESTINATION_SSFL\", \"SFL\"]\n",
    "final_results = pd.DataFrame(columns=out_cols)\n",
    "unique_edges = set()              # guarantees row-level uniqueness\n",
    "\n",
    "\n",
    "# 3.  SCADA â†’ HT-CABLE WALK\n",
    "\n",
    "target_folders = [\n",
    "    \"/media/sagarkumar/New Volume1/SAGAR/200/200\",\n",
    "    \"/media/sagarkumar/New Volume1/SAGAR/200-400/200-400\",\n",
    "    \"/media/sagarkumar/New Volume1/SAGAR/400-600/400-600\",\n",
    "    \"/media/sagarkumar/New Volume1/SAGAR/600-759/600-759\"\n",
    "]\n",
    "\n",
    "for folder in target_folders:\n",
    "    print(f\"  {folder}\")\n",
    "    for f in filter(lambda x: x.lower().endswith(\".csv\"), os.listdir(folder)):\n",
    "        scada_path = os.path.join(folder, f)\n",
    "        try:\n",
    "            scada = pd.read_csv(scada_path, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\"   â†³ skipped {f}: {e}\")\n",
    "            continue\n",
    "        if \"SWNO\" not in scada.columns:\n",
    "            print(f\"   â†³ skipped {f}: no SWNO column\")\n",
    "            continue\n",
    "\n",
    "        seen_swno = set()         # donâ€™t start the same chain twice\n",
    "\n",
    "        # â”€â”€ for each SW in the SCADA file\n",
    "        for swno in scada[\"SWNO\"].unique():\n",
    "            if swno in seen_swno:\n",
    "                continue\n",
    "            seen_swno.add(swno)\n",
    "\n",
    "            # first leg(s) : SOURCE_SWITCH_ID == SCADA swno\n",
    "            first_legs = htcable[htcable[\"SOURCE_SWITCH_ID\"] == swno]\n",
    "            if first_legs.empty:        # nothing to start with\n",
    "                continue\n",
    "\n",
    "            for _, first in first_legs.iterrows():\n",
    "                chain = []                              # holds one complete path\n",
    "                visited_ssfl = set()                    # loop guard\n",
    "\n",
    "                # push the very first edge\n",
    "                chain.append(first)\n",
    "\n",
    "                # walk forward\n",
    "                current_dest_ssfl = first[\"DESTINATION_SSFL\"]\n",
    "                while True:\n",
    "                    if current_dest_ssfl in visited_ssfl:\n",
    "                        break\n",
    "                    visited_ssfl.add(current_dest_ssfl)\n",
    "\n",
    "                    # Grab *all* next legs that start from this SSFL\n",
    "                    next_edges = (htcable\n",
    "                                  [htcable[\"SOURCE_SSFL\"] == current_dest_ssfl]\n",
    "                                  .sort_values([\"SOURCE_SWITCH_ID\",\n",
    "                                                \"DESTINATION_SWITCH_ID\"]))\n",
    "                    if next_edges.empty:\n",
    "                        break\n",
    "\n",
    "                    for _, edge in next_edges.iterrows():\n",
    "                        chain.append(edge)\n",
    "                        current_dest_ssfl = edge[\"DESTINATION_SSFL\"]\n",
    "\n",
    "                    # and loop again with the **last** destination just appended\n",
    "\n",
    "                # dump chain to output, edge by edge\n",
    "                for edge in chain:\n",
    "                    tup = (edge[\"SOURCE_SWITCH_ID\"],\n",
    "                           edge[\"DESTINATION_SWITCH_ID\"],\n",
    "                           edge[\"SOURCE_SSFL\"],\n",
    "                           edge[\"DESTINATION_SSFL\"])\n",
    "                    if tup in unique_edges:     # skip dup across all folders\n",
    "                        continue\n",
    "                    unique_edges.add(tup)\n",
    "\n",
    "                    final_results.loc[len(final_results)] = [\n",
    "                        f\"{edge['SOURCE_SWITCH_ID']}-{edge['DESTINATION_SWITCH_ID']}\",\n",
    "                        edge[\"SOURCE_SSFL\"],\n",
    "                        edge[\"DESTINATION_SSFL\"],\n",
    "                        edge[\"DESTINATION_SSFL\"]   # per your original spec\n",
    "                    ]\n",
    "\n",
    "\n",
    "# 4.  SAVE THE MERGED CHAINS\n",
    "\n",
    "out_file = \"scada_htcable_chain_all_folders_deduped.xlsx\"\n",
    "final_results.to_excel(out_file, index=False)\n",
    "print(f\"\\n  Done â€“ {len(final_results)} unique rows written to {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984287c",
   "metadata": {},
   "source": [
    "SAMLE OF ABOVE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder  /media/sagarkumar/New Volume/SAGAR/200/200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1.  PRE-PROCESS THE HT-CABLE FILE\n",
    "cols_to_drop = [\"COMMENTS\", \"GLOBALID\", \"MEASUREDLENGTH\",\n",
    "                \"Unnamed: 0\", \"OBJECTID\"]\n",
    "\n",
    "try:\n",
    "    htcable = (\n",
    "        pd.read_csv(\"HTCABLE.csv\", low_memory=False)\n",
    "          .drop(columns=cols_to_drop, errors=\"ignore\")      # throw away noisy cols\n",
    "          .drop_duplicates(subset=[\"SOURCE_SWITCH_ID\",\n",
    "                                    \"DESTINATION_SWITCH_ID\",\n",
    "                                    \"SOURCE_SSFL\",\n",
    "                                    \"DESTINATION_SSFL\"])      # keep only unique edges\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: HTCABLE.csv not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading or processing HTCABLE.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# 2.  PREPARE OUTPUT CONTAINER\n",
    "out_cols = [\"SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID\",\n",
    "            \"SOURCE_SSFL\", \"DESTINATION_SSFL\", \"SFL\"]\n",
    "final_results = pd.DataFrame(columns=out_cols)\n",
    "unique_edges = set()          # guarantees row-level uniqueness\n",
    "output_limit = 10000 # Define the output limit\n",
    "limit_reached = False # Flag to indicate if the limit has been reached\n",
    "\n",
    "# 3.  SCADA â†’ HT-CABLE WALK\n",
    "target_folders = [\n",
    "    \"/media/sagarkumar/New Volume/SAGAR/200/200\",\n",
    "    \"/media/sagarkumar/New Volume/SAGAR/200-400/200-400\",\n",
    "    \"/media/sagarkumar/New Volume/SAGAR/400-600/400-600\",\n",
    "    \"/media/sagarkumar/New Volume/SAGAR/600-759/600-759\"\n",
    "]\n",
    "\n",
    "for folder in target_folders:\n",
    "    if limit_reached:\n",
    "        break\n",
    "    print(f\"folder  {folder}\")\n",
    "    # Check if the folder exists\n",
    "    if not os.path.isdir(folder):\n",
    "        print(f\"  â†³ skipped folder {folder}: does not exist or is not a directory\")\n",
    "        continue\n",
    "\n",
    "    for f in filter(lambda x: x.lower().endswith(\".csv\"), os.listdir(folder)):\n",
    "        if limit_reached:\n",
    "            break\n",
    "        scada_path = os.path.join(folder, f)\n",
    "        try:\n",
    "            scada = pd.read_csv(scada_path, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\"    â†³ skipped {f}: {e}\")\n",
    "            continue\n",
    "        if \"SWNO\" not in scada.columns:\n",
    "            print(f\"    â†³ skipped {f}: no SWNO column\")\n",
    "            continue\n",
    "\n",
    "        seen_swno = set()      # donâ€™t start the same chain twice\n",
    "\n",
    "        # â”€â”€ for each SW in the SCADA file\n",
    "        for swno in scada[\"SWNO\"].unique():\n",
    "            if limit_reached:\n",
    "                break\n",
    "            if swno in seen_swno:\n",
    "                continue\n",
    "            seen_swno.add(swno)\n",
    "\n",
    "            # first leg(s) : SOURCE_SWITCH_ID == SCADA swno\n",
    "            first_legs = htcable[htcable[\"SOURCE_SWITCH_ID\"] == swno]\n",
    "            if first_legs.empty:      # nothing to start with\n",
    "                continue\n",
    "\n",
    "            for _, first in first_legs.iterrows():\n",
    "                if limit_reached:\n",
    "                    break\n",
    "                chain = []                                  # holds one complete path\n",
    "                visited_ssfl = set()                        # loop guard\n",
    "\n",
    "                # push the very first edge\n",
    "                chain.append(first)\n",
    "\n",
    "                # walk forward\n",
    "                current_dest_ssfl = first[\"DESTINATION_SSFL\"]\n",
    "                while True: # Inner loop for walking the chain\n",
    "                    if current_dest_ssfl in visited_ssfl:\n",
    "                        break # Break from inner while loop (loop guard)\n",
    "                    visited_ssfl.add(current_dest_ssfl)\n",
    "\n",
    "                    # Grab *all* next legs that start from this SSFL\n",
    "                    next_edges = (htcable\n",
    "                                  [htcable[\"SOURCE_SSFL\"] == current_dest_ssfl]\n",
    "                                  .sort_values([\"SOURCE_SWITCH_ID\",\n",
    "                                                \"DESTINATION_SWITCH_ID\"]))\n",
    "                    if next_edges.empty:\n",
    "                        break # Break from inner while loop (no more edges)\n",
    "\n",
    "                    # In the original script, it iterates through all next_edges and appends the last one's destination.\n",
    "                    # This logic implies that a chain can branch, but the original code only follows the last branch.\n",
    "                    # For simplicity and to match the original apparent intent, we'll take the last edge from next_edges.\n",
    "                    # If multiple branches need to be explored independently, the logic here would need significant changes (e.g., recursion or a stack).\n",
    "\n",
    "                    # Append all edges found from this SSFL (if this was the intent for multiple branches)\n",
    "                    # For now, let's stick to the original logic where current_dest_ssfl is updated by the last edge in next_edges.\n",
    "                    last_edge_appended_to_chain = False\n",
    "                    for _, edge in next_edges.iterrows():\n",
    "                        chain.append(edge)\n",
    "                        current_dest_ssfl = edge[\"DESTINATION_SSFL\"] # This will be updated multiple times if next_edges has more than one row.\n",
    "                                                                    # The while loop then continues with the DESTINATION_SSFL of the *last* edge.\n",
    "                        last_edge_appended_to_chain = True\n",
    "\n",
    "                    if not last_edge_appended_to_chain: # Should not happen if next_edges was not empty\n",
    "                        break\n",
    "                    # and loop again with the **last** destination just appended\n",
    "\n",
    "                # dump chain to output, edge by edge\n",
    "                for edge in chain:\n",
    "                    if len(final_results) >= output_limit:\n",
    "                        limit_reached = True\n",
    "                        break # Break from chain dump loop\n",
    "\n",
    "                    tup = (edge[\"SOURCE_SWITCH_ID\"],\n",
    "                           edge[\"DESTINATION_SWITCH_ID\"],\n",
    "                           edge[\"SOURCE_SSFL\"],\n",
    "                           edge[\"DESTINATION_SSFL\"])\n",
    "                    if tup in unique_edges:      # skip dup across all folders\n",
    "                        continue\n",
    "                    unique_edges.add(tup)\n",
    "\n",
    "                    final_results.loc[len(final_results)] = [\n",
    "                        f\"{edge['SOURCE_SWITCH_ID']}-{edge['DESTINATION_SWITCH_ID']}\",\n",
    "                        edge[\"SOURCE_SSFL\"],\n",
    "                        edge[\"DESTINATION_SSFL\"],\n",
    "                        edge[\"DESTINATION_SSFL\"]  # per your original spec\n",
    "                    ]\n",
    "                if limit_reached: # propagate break\n",
    "                    break # from first_legs loop\n",
    "            if limit_reached: # propagate break\n",
    "                break # from swno loop\n",
    "        if limit_reached: # propagate break\n",
    "            break # from files loop\n",
    "    if limit_reached: # propagate break\n",
    "        break # from folders loop\n",
    "\n",
    "\n",
    "# 4.  SAVE THE MERGED CHAINS\n",
    "out_file = \"scada_htcable_chain_limited_output.xlsx\"\n",
    "try:\n",
    "    final_results.to_excel(out_file, index=False)\n",
    "    print(f\"\\n  Done â€“ {len(final_results)} rows written to {out_file}\")\n",
    "    if limit_reached and len(final_results) >= output_limit:\n",
    "        print(f\"Output was limited to {output_limit} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to Excel file {out_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# (Assume `htcable` is already loaded as before.)\n",
    "\n",
    "def main():\n",
    "    data_folders = [\n",
    "        \"/media/sagarkumar/New Volume/SAGAR/200/200\",\n",
    "        \"/media/sagarkumar/New Volume/SAGAR/200-400/200-400\",\n",
    "        \"/media/sagarkumar/New Volume/SAGAR/400-600/400-600\",\n",
    "        \"/media/sagarkumar/New Volume/SAGAR/600-759/600-759\",\n",
    "    ]\n",
    "\n",
    "    # 1) Gather all CSV paths\n",
    "    all_scada_paths = []\n",
    "    for folder in data_folders:\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"â†³ Skipping nonexistent folder {folder}\")\n",
    "            continue\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.lower().endswith(\".csv\"):\n",
    "                all_scada_paths.append(os.path.join(folder, fname))\n",
    "\n",
    "    if not all_scada_paths:\n",
    "        print(\"No SCADA files found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 2) Kick off parallel workers\n",
    "    max_workers = min(os.cpu_count() or 1, 8)\n",
    "    futures = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as exe:\n",
    "        for scada_path in all_scada_paths:\n",
    "            futures.append(\n",
    "                exe.submit(process_single_scada_file, scada_path, htcable)\n",
    "            )\n",
    "\n",
    "        # 3) As each worker finishes, collect its rows\n",
    "        all_partial = []\n",
    "        for fut in as_completed(futures):\n",
    "            try:\n",
    "                rows = fut.result()\n",
    "            except Exception as e:\n",
    "                print(\"  â†³ Worker error:\", e)\n",
    "                continue\n",
    "            if rows:\n",
    "                all_partial.extend(rows)\n",
    "\n",
    "    # 4) Globally dedupe + enforce 20 000â€row limit\n",
    "    unique_global = set()\n",
    "    final_rows = []\n",
    "    limit = 20000\n",
    "    for row in all_partial:\n",
    "        if len(final_rows) >= limit:\n",
    "            break\n",
    "        src, dst = row[\"SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID\"].split(\"-\")\n",
    "        tup = (int(src), int(dst),\n",
    "               float(row[\"SOURCE_SSFL\"]),\n",
    "               float(row[\"DESTINATION_SSFL\"]))\n",
    "        if tup in unique_global:\n",
    "            continue\n",
    "        unique_global.add(tup)\n",
    "        final_rows.append(row)\n",
    "\n",
    "    # 5) Build DataFrame & write Excel\n",
    "    df_out = pd.DataFrame(final_rows, columns=[\n",
    "        \"SOURCE_SWITCH_ID-DESTINATION_SWITCH_ID\",\n",
    "        \"SOURCE_SSFL\", \"DESTINATION_SSFL\", \"SFL\"\n",
    "    ])\n",
    "    df_out.to_excel(\"scada_htcable_chain_limited_outputp.xlsx\", index=False)\n",
    "    print(f\"Exported {len(df_out)} rows.{' (LIMITED to 20 000.)' if len(df_out) >= limit else ''}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
