{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb24f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 933 rows → /media/sagarkumar/New Volume/SAGAR/IPYNB_FILE/DATA_GENERATION/feeder_trace_22_33kv.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEEDER_ID</th>\n",
       "      <th>FROM_TO</th>\n",
       "      <th>SOURCE_SSFL</th>\n",
       "      <th>DESTINATION_SSFL</th>\n",
       "      <th>LATEST_DT_DATE</th>\n",
       "      <th>DT_LOAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220AAR02</td>\n",
       "      <td>220AAR92-33099</td>\n",
       "      <td>1S-MH-MU-ZSC-CL10-3581</td>\n",
       "      <td>1S-MH-MU-ZET-RSTN-HIRA</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>200.446784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220AAR05</td>\n",
       "      <td>220AAR05-CAP BANK</td>\n",
       "      <td>1T-MH-MU-ARY</td>\n",
       "      <td>1T-MH-MU-ARY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220AAR100</td>\n",
       "      <td>220AAR100-CAP BANK</td>\n",
       "      <td>1T-MH-MU-ARY</td>\n",
       "      <td>1T-MH-MU-ARY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220AAR102</td>\n",
       "      <td>220AAR102-33008</td>\n",
       "      <td>1T-MH-MU-ARY</td>\n",
       "      <td>1S-MH-MU-ZST-RSTN-VILE</td>\n",
       "      <td>2011-08-17</td>\n",
       "      <td>36.819512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>220AAR102</td>\n",
       "      <td>11435-31090</td>\n",
       "      <td>1S-MH-MU-ZST-RSTN-VILE</td>\n",
       "      <td>1S-MH-MU-ZST-RSTN-VILE</td>\n",
       "      <td>2011-08-17</td>\n",
       "      <td>36.819512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FEEDER_ID             FROM_TO             SOURCE_SSFL  \\\n",
       "0    220AAR02      220AAR92-33099  1S-MH-MU-ZSC-CL10-3581   \n",
       "2    220AAR05   220AAR05-CAP BANK            1T-MH-MU-ARY   \n",
       "3   220AAR100  220AAR100-CAP BANK            1T-MH-MU-ARY   \n",
       "4   220AAR102     220AAR102-33008            1T-MH-MU-ARY   \n",
       "75  220AAR102         11435-31090  1S-MH-MU-ZST-RSTN-VILE   \n",
       "\n",
       "          DESTINATION_SSFL LATEST_DT_DATE     DT_LOAD  \n",
       "0   1S-MH-MU-ZET-RSTN-HIRA     2025-02-07  200.446784  \n",
       "2             1T-MH-MU-ARY            NaT         NaN  \n",
       "3             1T-MH-MU-ARY            NaT         NaN  \n",
       "4   1S-MH-MU-ZST-RSTN-VILE     2011-08-17   36.819512  \n",
       "75  1S-MH-MU-ZST-RSTN-VILE     2011-08-17   36.819512  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- CONFIG\n",
    "INPUT_HT = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/HTCABLE_Clean.csv\"\n",
    "INPUT_ENERGY = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/ENERGYAUDIT.csv\"\n",
    "OUTPUT_PATH = \"/media/sagarkumar/New Volume/SAGAR/IPYNB_FILE/DATA_GENERATION/feeder_trace_22_33kv.csv\"\n",
    "\n",
    "FEEDER_ID_COL = \"FEEDERID\"\n",
    "SRC_SWITCH_COL = \"SOURCE_SWITCH_ID\"\n",
    "DST_SWITCH_COL = \"DESTINATION_SWITCH_ID\"\n",
    "SRC_LOC_COL = \"SOURCE_SSFL\"\n",
    "DST_LOC_COL = \"DESTINATION_SSFL\"\n",
    "FUNC_LOC_COL = \"FUNC_LOC\"\n",
    "DATE_COL = \"SYSTEM_DATE\"\n",
    "LOAD_COL = \"MD_KVA\"\n",
    "\n",
    "# --- LOAD HTCABLE.csv\n",
    "ht = pd.read_csv(INPUT_HT, low_memory=False)\n",
    "\n",
    "# Function to extract feeder token for 22kV/33kV only (case-insensitive)\n",
    "def feeder_token_22_33(val):\n",
    "    if not isinstance(val, str):\n",
    "        val = str(val) if val is not None else \"\"\n",
    "    p = val.upper().split(\"_\")\n",
    "    if len(p) >= 3 and p[1] in {'22KV', '33KV'}:\n",
    "        return p[2]\n",
    "    return None\n",
    "\n",
    "ht[\"FEEDER_ID\"] = ht[FEEDER_ID_COL].apply(feeder_token_22_33)\n",
    "ht = ht[ht[\"FEEDER_ID\"].notna()]  # Keep only 22kV/33kV feeders\n",
    "\n",
    "# Build FROM_TO column as \"SRC_SWITCH_ID-DST_SWITCH_ID\"\n",
    "ht[\"FROM_TO\"] = ht[SRC_SWITCH_COL].astype(str) + \"-\" + ht[DST_SWITCH_COL].astype(str)\n",
    "\n",
    "# --- LOAD ENERGYAUDIT.csv and aggregate\n",
    "audit = pd.read_csv(INPUT_ENERGY, low_memory=False, parse_dates=[DATE_COL])\n",
    "audit.columns = [c.upper() for c in audit.columns]\n",
    "audit[DATE_COL] = pd.to_datetime(audit[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "audit = audit[[FUNC_LOC_COL, DATE_COL, LOAD_COL]].dropna(subset=[FUNC_LOC_COL])\n",
    "agg = (audit.groupby(FUNC_LOC_COL)\n",
    "           .agg(LATEST_DT_DATE=(DATE_COL, \"max\"),\n",
    "                DT_LOAD=(LOAD_COL,  \"mean\"))\n",
    "           .reset_index())\n",
    "agg[FUNC_LOC_COL] = agg[FUNC_LOC_COL].astype(str)\n",
    "\n",
    "# --- MERGE by DESTINATION_SSFL = FUNC_LOC\n",
    "ht[SRC_LOC_COL] = ht[SRC_LOC_COL].astype(str)\n",
    "ht[DST_LOC_COL] = ht[DST_LOC_COL].astype(str)\n",
    "merged = ht.merge(agg, how=\"left\", left_on=DST_LOC_COL, right_on=FUNC_LOC_COL)\n",
    "\n",
    "# --- OUTPUT ONLY NEEDED COLUMNS\n",
    "final_cols = [\n",
    "    \"FEEDER_ID\",\n",
    "    \"FROM_TO\",\n",
    "    SRC_LOC_COL,\n",
    "    DST_LOC_COL,\n",
    "    \"LATEST_DT_DATE\",\n",
    "    \"DT_LOAD\"\n",
    "]\n",
    "merged = merged[final_cols]\n",
    "\n",
    "# --- REMOVE DUPLICATE ROWS\n",
    "merged = merged.drop_duplicates()\n",
    "\n",
    "# --- EXPORT\n",
    "merged.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Saved {len(merged):,} rows → {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(merged.head())\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa2215",
   "metadata": {},
   "source": [
    "NOT 11 33 and 22 KV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2365c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 969 rows → /media/sagarkumar/New Volume/SAGAR/IPYNB_FILE/DATA_GENERATION/feeder_trace_not_11_22_33kv_fullid.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEEDER_ID</th>\n",
       "      <th>FROM_TO</th>\n",
       "      <th>SOURCE_SSFL</th>\n",
       "      <th>DESTINATION_SSFL</th>\n",
       "      <th>LATEST_DT_DATE</th>\n",
       "      <th>DT_LOAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29916-16915</td>\n",
       "      <td>1S-MH-MU-ZSC-CL08-3108</td>\n",
       "      <td>1S-MH-MU-ZSC-CL08-2843</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>388.498522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11292-2052</td>\n",
       "      <td>nan</td>\n",
       "      <td>1S-MH-MU-ZET-CL06-8690</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>192.449655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3136-14325</td>\n",
       "      <td>1S-MH-MU-ZET-RSTN-SAKI</td>\n",
       "      <td>1S-MH-MU-ZSC-RSTN-AARE</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>238.494349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3136-14325</td>\n",
       "      <td>1S-MH-MU-ZET-RSTN-SAKI</td>\n",
       "      <td>1T-MH-MU-ARY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25270-25271</td>\n",
       "      <td>1S-MH-MU-ZET-RSTN-CHEM</td>\n",
       "      <td>1S-MH-MU-ZET-RSTN-CHEM</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>462.579397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FEEDER_ID      FROM_TO             SOURCE_SSFL        DESTINATION_SSFL  \\\n",
       "0        NaN  29916-16915  1S-MH-MU-ZSC-CL08-3108  1S-MH-MU-ZSC-CL08-2843   \n",
       "2        NaN   11292-2052                     nan  1S-MH-MU-ZET-CL06-8690   \n",
       "3        NaN   3136-14325  1S-MH-MU-ZET-RSTN-SAKI  1S-MH-MU-ZSC-RSTN-AARE   \n",
       "4        NaN   3136-14325  1S-MH-MU-ZET-RSTN-SAKI            1T-MH-MU-ARY   \n",
       "29       NaN  25270-25271  1S-MH-MU-ZET-RSTN-CHEM  1S-MH-MU-ZET-RSTN-CHEM   \n",
       "\n",
       "   LATEST_DT_DATE     DT_LOAD  \n",
       "0      2025-04-04  388.498522  \n",
       "2      2025-04-04  192.449655  \n",
       "3      2025-04-04  238.494349  \n",
       "4             NaT         NaN  \n",
       "29     2025-02-07  462.579397  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIG\n",
    "INPUT_HT = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/HTCABLE_Clean.csv\"\n",
    "INPUT_ENERGY = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/ENERGYAUDIT.csv\"\n",
    "OUTPUT_PATH = \"/media/sagarkumar/New Volume/SAGAR/IPYNB_FILE/DATA_GENERATION/feeder_trace_not_11_22_33kv_fullid.csv\"\n",
    "\n",
    "FEEDER_ID_COL = \"FEEDERID\"\n",
    "SRC_SWITCH_COL = \"SOURCE_SWITCH_ID\"\n",
    "DST_SWITCH_COL = \"DESTINATION_SWITCH_ID\"\n",
    "SRC_LOC_COL = \"SOURCE_SSFL\"\n",
    "DST_LOC_COL = \"DESTINATION_SSFL\"\n",
    "FUNC_LOC_COL = \"FUNC_LOC\"\n",
    "DATE_COL = \"SYSTEM_DATE\"\n",
    "LOAD_COL = \"MD_KVA\"\n",
    "\n",
    "# --- LOAD HTCABLE.csv\n",
    "ht = pd.read_csv(INPUT_HT, low_memory=False)\n",
    "\n",
    "# Only filter: keep full FEEDERID if NOT 11KV/22KV/33KV anywhere in string\n",
    "def is_not_11_22_33kv(feederid):\n",
    "    if not isinstance(feederid, str):\n",
    "        feederid = str(feederid) if feederid is not None else \"\"\n",
    "    s = feederid.upper()\n",
    "    if any(k in s for k in ['_11KV_', '_22KV_', '_33KV_']):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "ht = ht[ht[FEEDER_ID_COL].apply(is_not_11_22_33kv)].copy()\n",
    "ht[\"FEEDER_ID\"] = ht[FEEDER_ID_COL]  # Just copy the full original value\n",
    "\n",
    "# Build FROM_TO column as \"SRC_SWITCH_ID-DST_SWITCH_ID\"\n",
    "ht[\"FROM_TO\"] = ht[SRC_SWITCH_COL].astype(str) + \"-\" + ht[DST_SWITCH_COL].astype(str)\n",
    "\n",
    "# --- LOAD ENERGYAUDIT.csv and aggregate\n",
    "audit = pd.read_csv(INPUT_ENERGY, low_memory=False, parse_dates=[DATE_COL])\n",
    "audit.columns = [c.upper() for c in audit.columns]\n",
    "audit[DATE_COL] = pd.to_datetime(audit[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "audit = audit[[FUNC_LOC_COL, DATE_COL, LOAD_COL]].dropna(subset=[FUNC_LOC_COL])\n",
    "agg = (audit.groupby(FUNC_LOC_COL)\n",
    "           .agg(LATEST_DT_DATE=(DATE_COL, \"max\"),\n",
    "                DT_LOAD=(LOAD_COL,  \"mean\"))\n",
    "           .reset_index())\n",
    "agg[FUNC_LOC_COL] = agg[FUNC_LOC_COL].astype(str)\n",
    "\n",
    "# --- MERGE by DESTINATION_SSFL = FUNC_LOC\n",
    "ht[SRC_LOC_COL] = ht[SRC_LOC_COL].astype(str)\n",
    "ht[DST_LOC_COL] = ht[DST_LOC_COL].astype(str)\n",
    "merged = ht.merge(agg, how=\"left\", left_on=DST_LOC_COL, right_on=FUNC_LOC_COL)\n",
    "\n",
    "# --- OUTPUT ONLY NEEDED COLUMNS\n",
    "final_cols = [\n",
    "    \"FEEDER_ID\",\n",
    "    \"FROM_TO\",\n",
    "    SRC_LOC_COL,\n",
    "    DST_LOC_COL,\n",
    "    \"LATEST_DT_DATE\",\n",
    "    \"DT_LOAD\"\n",
    "]\n",
    "merged = merged[final_cols]\n",
    "\n",
    "# --- REMOVE DUPLICATE ROWS\n",
    "merged = merged.drop_duplicates()\n",
    "\n",
    "# --- EXPORT\n",
    "merged.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Saved {len(merged):,} rows → {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(merged.head())\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973ad87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
