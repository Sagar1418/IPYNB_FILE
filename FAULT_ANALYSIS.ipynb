{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227ac71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2e4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_HT = pd.read_csv(\"/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv\" ,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a8831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_apr = pd.read_csv(\"/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_Logsheet_April 2025.csv\" ,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b9abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv...\n",
      "  - Found 5145 unique, clean values.\n",
      "Processing file: /media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_Logsheet_April 2025.csv...\n",
      "  - Found 199 unique, clean values.\n",
      "\n",
      "--- Comparison Report ---\n",
      "Unique values in '/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv' (Column: SWITCH_NO): 5145\n",
      "Unique values in '/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_Logsheet_April 2025.csv' (Column: SWITCH_NO): 199\n",
      "-------------------------\n",
      "Number of values that matched: 177\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION: PLEASE EDIT THIS SECTION ---\n",
    "\n",
    "# File 1 Details\n",
    "file1_path = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv\"\n",
    "file1_column_name = \"SWITCH_NO\"  \n",
    "\n",
    "# File 2 Details\n",
    "file2_path = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_Logsheet_April 2025.csv\"\n",
    "file2_column_name = \"SWITCH_NO\" \n",
    "\n",
    "\n",
    "def find_actual_column_name(columns, target_name):\n",
    "    \"\"\"Helper function to find a column name, ignoring case.\"\"\"\n",
    "    for col in columns:\n",
    "        if str(col).lower() == str(target_name).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def get_unique_values_from_file(filepath, column_name):\n",
    "    \"\"\"\n",
    "    Reads a file, extracts unique values from a specific column,\n",
    "    cleans them, and returns them as a set.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}...\")\n",
    "    try:\n",
    "        # Read just the header to find the correct column name (case-insensitive)\n",
    "        header_df = pd.read_csv(filepath, nrows=0, on_bad_lines='skip')\n",
    "        actual_col_name = find_actual_column_name(header_df.columns, column_name)\n",
    "\n",
    "        if not actual_col_name:\n",
    "            print(f\"  - Error: Column '{column_name}' not found. Please check the column name.\")\n",
    "            return set()\n",
    "\n",
    "        # Read the full column using the correct name\n",
    "        df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip')\n",
    "        \n",
    "        # --- Data Cleaning ---\n",
    "        # Convert all values to string, extract digits, and then convert to numbers.\n",
    "        # This handles mixed data types (e.g., '123' vs 123) and text prefixes (e.g., 'SW-123').\n",
    "        s = pd.Series(df[actual_col_name].dropna().unique(), dtype=str)\n",
    "        s = s.str.extract('(\\d+)').iloc[:, 0]\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "        \n",
    "        cleaned_values = set(s.dropna().astype(int))\n",
    "        \n",
    "        print(f\"  - Found {len(cleaned_values)} unique, clean values.\")\n",
    "        return cleaned_values\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - Error: File not found. Please check the path: {filepath}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"  - An unexpected error occurred: {e}\")\n",
    "        return set()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Get the unique values from both files\n",
    "unique_values_from_file1 = get_unique_values_from_file(file1_path, file1_column_name)\n",
    "unique_values_from_file2 = get_unique_values_from_file(file2_path, file2_column_name)\n",
    "\n",
    "# --- Comparison and Reporting ---\n",
    "\n",
    "print(\"\\n--- Comparison Report ---\")\n",
    "if not unique_values_from_file1 or not unique_values_from_file2:\n",
    "    print(\"Could not perform comparison because one of the files could not be processed or contained no valid data.\")\n",
    "else:\n",
    "    # Use set intersection to find the values that exist in both sets\n",
    "    matching_values = unique_values_from_file1.intersection(unique_values_from_file2)\n",
    "    \n",
    "    # Print the final report\n",
    "    print(f\"Unique values in '{file1_path}' (Column: {file1_column_name}): {len(unique_values_from_file1)}\")\n",
    "    print(f\"Unique values in '{file2_path}' (Column: {file2_column_name}): {len(unique_values_from_file2)}\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Number of values that matched: {len(matching_values)}\")\n",
    "    print(\"-\" * 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d87a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv...\n",
      "  - Found 5145 unique, clean values.\n",
      "Processing file: /media/sagarkumar/New Volume/SAGAR/IPYNB_FILE/CSV FILE/EXETRA FILES/feeder_ids_list_11kv.csv...\n",
      "  - Found 1191 unique, clean values.\n",
      "\n",
      "--- Comparison Report ---\n",
      "Unique values in '/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv' (Column: SWITCH_NO): 5145\n",
      "Unique values in '/media/sagarkumar/New Volume/SAGAR/IPYNB_FILE/CSV FILE/EXETRA FILES/feeder_ids_list_11kv.csv' (Column: FEEDER): 1191\n",
      "-------------------------\n",
      "Number of values that matched: 978\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION: PLEASE EDIT THIS SECTION ---\n",
    "\n",
    "# File 1 Details\n",
    "file1_path = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv\"\n",
    "file1_column_name = \"SWITCH_NO\"  \n",
    "\n",
    "# File 2 Details\n",
    "file2_path = \"/media/sagarkumar/New Volume/SAGAR/IPYNB_FILE/CSV FILE/EXETRA FILES/feeder_ids_list_11kv.csv\"\n",
    "file2_column_name = \"FEEDER\"\n",
    "\n",
    "\n",
    "def find_actual_column_name(columns, target_name):\n",
    "    \"\"\"Helper function to find a column name, ignoring case.\"\"\"\n",
    "    for col in columns:\n",
    "        if str(col).lower() == str(target_name).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def get_unique_values_from_file(filepath, column_name):\n",
    "    \"\"\"\n",
    "    Reads a file, extracts unique values from a specific column,\n",
    "    cleans them, and returns them as a set.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}...\")\n",
    "    try:\n",
    "        # Read just the header to find the correct column name (case-insensitive)\n",
    "        header_df = pd.read_csv(filepath, nrows=0, on_bad_lines='skip')\n",
    "        actual_col_name = find_actual_column_name(header_df.columns, column_name)\n",
    "\n",
    "        if not actual_col_name:\n",
    "            print(f\"  - Error: Column '{column_name}' not found. Please check the column name.\")\n",
    "            return set()\n",
    "\n",
    "        # Read the full column using the correct name\n",
    "        df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip')\n",
    "        \n",
    "        # --- Data Cleaning ---\n",
    "        # Convert all values to string, extract digits, and then convert to numbers.\n",
    "        # This handles mixed data types (e.g., '123' vs 123) and text prefixes (e.g., 'SW-123').\n",
    "        s = pd.Series(df[actual_col_name].dropna().unique(), dtype=str)\n",
    "        s = s.str.extract('(\\d+)').iloc[:, 0]\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "        \n",
    "        cleaned_values = set(s.dropna().astype(int))\n",
    "        \n",
    "        print(f\"  - Found {len(cleaned_values)} unique, clean values.\")\n",
    "        return cleaned_values\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - Error: File not found. Please check the path: {filepath}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"  - An unexpected error occurred: {e}\")\n",
    "        return set()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Get the unique values from both files\n",
    "unique_values_from_file1 = get_unique_values_from_file(file1_path, file1_column_name)\n",
    "unique_values_from_file2 = get_unique_values_from_file(file2_path, file2_column_name)\n",
    "\n",
    "# --- Comparison and Reporting ---\n",
    "\n",
    "print(\"\\n--- Comparison Report ---\")\n",
    "if not unique_values_from_file1 or not unique_values_from_file2:\n",
    "    print(\"Could not perform comparison because one of the files could not be processed or contained no valid data.\")\n",
    "else:\n",
    "    # Use set intersection to find the values that exist in both sets\n",
    "    matching_values = unique_values_from_file1.intersection(unique_values_from_file2)\n",
    "    \n",
    "    # Print the final report\n",
    "    print(f\"Unique values in '{file1_path}' (Column: {file1_column_name}): {len(unique_values_from_file1)}\")\n",
    "    print(f\"Unique values in '{file2_path}' (Column: {file2_column_name}): {len(unique_values_from_file2)}\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Number of values that matched: {len(matching_values)}\")\n",
    "    print(\"-\" * 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf4491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv...\n",
      "  - Found 1098 unique, clean values.\n",
      "Processing file: /media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_Logsheet_April 2025.csv...\n",
      "  - Found 41 unique, clean values.\n",
      "\n",
      "--- Comparison Report ---\n",
      "Unique values in '/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv' (Column: FREE_REMARKS): 1098\n",
      "Unique values in '/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_Logsheet_April 2025.csv' (Column: FREE_REMARKS): 41\n",
      "-------------------------\n",
      "Number of values that matched: 26\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION: PLEASE EDIT THIS SECTION ---\n",
    "\n",
    "# File 1 Details\n",
    "file1_path = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_HTLOGSHEET.csv\"\n",
    "file1_column_name = \"FREE_REMARKS\" \n",
    "\n",
    "# File 2 Details\n",
    "file2_path = \"/media/sagarkumar/New Volume/SAGAR/2-year-data/TXN_NMS_Logsheet_April 2025.csv\"\n",
    "file2_column_name = \"FREE_REMARKS\" \n",
    "\n",
    "\n",
    "def find_actual_column_name(columns, target_name):\n",
    "    \"\"\"Helper function to find a column name, ignoring case.\"\"\"\n",
    "    for col in columns:\n",
    "        if str(col).lower() == str(target_name).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def get_unique_values_from_file(filepath, column_name):\n",
    "    \"\"\"\n",
    "    Reads a file, extracts unique values from a specific column,\n",
    "    cleans them, and returns them as a set.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}...\")\n",
    "    try:\n",
    "        # Read just the header to find the correct column name (case-insensitive)\n",
    "        header_df = pd.read_csv(filepath, nrows=0, on_bad_lines='skip')\n",
    "        actual_col_name = find_actual_column_name(header_df.columns, column_name)\n",
    "\n",
    "        if not actual_col_name:\n",
    "            print(f\"  - Error: Column '{column_name}' not found. Please check the column name.\")\n",
    "            return set()\n",
    "\n",
    "        # Read the full column using the correct name\n",
    "        df = pd.read_csv(filepath, usecols=[actual_col_name], on_bad_lines='skip')\n",
    "        \n",
    "        # --- Data Cleaning ---\n",
    "        # Convert all values to string, extract digits, and then convert to numbers.\n",
    "        # This handles mixed data types (e.g., '123' vs 123) and text prefixes (e.g., 'SW-123').\n",
    "        s = pd.Series(df[actual_col_name].dropna().unique(), dtype=str)\n",
    "        s = s.str.extract('(\\d+)').iloc[:, 0]\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "        \n",
    "        cleaned_values = set(s.dropna().astype(int))\n",
    "        \n",
    "        print(f\"  - Found {len(cleaned_values)} unique, clean values.\")\n",
    "        return cleaned_values\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - Error: File not found. Please check the path: {filepath}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"  - An unexpected error occurred: {e}\")\n",
    "        return set()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Get the unique values from both files\n",
    "unique_values_from_file1 = get_unique_values_from_file(file1_path, file1_column_name)\n",
    "unique_values_from_file2 = get_unique_values_from_file(file2_path, file2_column_name)\n",
    "\n",
    "# --- Comparison and Reporting ---\n",
    "\n",
    "print(\"\\n--- Comparison Report ---\")\n",
    "if not unique_values_from_file1 or not unique_values_from_file2:\n",
    "    print(\"Could not perform comparison because one of the files could not be processed or contained no valid data.\")\n",
    "else:\n",
    "    # Use set intersection to find the values that exist in both sets\n",
    "    matching_values = unique_values_from_file1.intersection(unique_values_from_file2)\n",
    "    \n",
    "    # Print the final report\n",
    "    print(f\"Unique values in '{file1_path}' (Column: {file1_column_name}): {len(unique_values_from_file1)}\")\n",
    "    print(f\"Unique values in '{file2_path}' (Column: {file2_column_name}): {len(unique_values_from_file2)}\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Number of values that matched: {len(matching_values)}\")\n",
    "    print(\"-\" * 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4c600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df_log_HT[df_log_HT[\"ENTRY_TYPE\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69246b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11073"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ccbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = df_log_HT['ENTRY_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ba2a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col['ENTRY_TYPE'].unique()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd9508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
