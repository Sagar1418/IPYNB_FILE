{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72087ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c4d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['220 kV AAREY EHV STATION' 'AAREY 220 KV RECEIVING STATION'\n",
      " '220kV SAKI REC-STN' '220kV GOREGAON REC-STN' '220kV VERSOVA REC-STN'\n",
      " 'MAHANANDA REC-STN' 'NESCO RECEIVING STATION' 'SAHAR PLAZA REC-STN'\n",
      " \"TATA'S DHARAVI REC-STN\" \"TATA'S MALAD REC-STN\" \"TATA'S BORIVALI REC-STN\"\n",
      " \"TATA's DHARAVI REC-STN\" \"TATA'S SAKI REC-STN\" \"TATA'S VERSOVA REC-STN\"\n",
      " \"TATA'S VIKHROLI REC-STN\" 'AAREY 220KV R/S' 'GOKULDHAM REC-STN'\n",
      " 'HINDUSTAN UNILEVER REC-STN' 'TATA BKC REC-STN' '220kV BORIVALI REC-STN'\n",
      " 'DAHISAR REC-STN' 'KANAKIA CCI REC-STN' 'SHIMPOLI REC-STN'\n",
      " 'BORIVALI REC-STN' '220kV CHEMBUR REC-STN' '220KV CHEMBUR REC-STN'\n",
      " \"TATA'S CHEMBUR REC-STN\" 'PALI REC-STN' 'BOMBILWADI REC-STN'\n",
      " 'POISAR REC-STN' '220kV GHODBUNDER REC-STN' 'DAHISAR WEST REC-STN'\n",
      " 'DEVIDAS LANE REC-STN' 'MIRA REC-STN' 'BHAYANDAR WEST REC-STN'\n",
      " 'VINAMRA REC-STN' 'SHANTI STAR MIRA REC-STN' 'RAVI MHADA REC-STN'\n",
      " 'SADGURU REC-STN' '220kV GORAI REC-STN' 'VAZIRA REC-STN' 'K.I.E. REC-STN'\n",
      " 'GORAI REC-STN' 'NIRLON REC-STN' 'MAHANANDA' \"TATA'S KURLA REC-STN\"\n",
      " \"TATA'S MANKHURD REC-STN\" 'MAROL REC-STN' \"TATA'S POWAI REC-STN\"\n",
      " 'NAHAR SHAKTI REC-STN' 'RIL REC-STN' 'TPC SAHAR RECEIVING STATION'\n",
      " 'MIAL T-2 DSS REC-STN' 'M.I.D.C. REC-STN' 'NETMAGIC DC-9 NO 1 BUS 2 DSS'\n",
      " 'NETMAGIC DC-9 NO 1 RECEIVING STATIO' 'ERANGLE REC-STN' 'JUHU REC-STN'\n",
      " nan]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/SWNO_MASTER_COMBINED_FULL.csv\", dtype=str)\n",
    "col = df['SOURCE_SS'].unique()\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e701f47",
   "metadata": {},
   "source": [
    "| **Standardized Name** | **All Variants Found**                                                           | **Count** |\n",
    "| --------------------- | -------------------------------------------------------------------------------- | --------- |\n",
    "| AAREY 220KV R/S       | `'220 kV AAREY EHV STATION'`, `'AAREY 220KV R/S'`                                | 2         |\n",
    "| SAKI REC-STN          | `'220kV SAKI REC-STN'`, `\"TATA'S SAKI REC-STN\"`                                  | 2         |\n",
    "| TATA DHARAVI REC-STN  | `\"TATA'S DHARAVI REC-STN\"`, `\"TATA's DHARAVI REC-STN\"`                           | 2         |\n",
    "| VERSOVA REC-STN       | `'220kV VERSOVA REC-STN'`, `\"TATA'S VERSOVA REC-STN\"`                            | 2         |\n",
    "| CHEMBUR REC-STN       | `'220kV CHEMBUR REC-STN'`, `'220KV CHEMBUR REC-STN'`, `\"TATA'S CHEMBUR REC-STN\"` | 3         |\n",
    "| BORIVALI REC-STN      | `'220kV BORIVALI REC-STN'`, `'BORIVALI REC-STN'`, `\"TATA'S BORIVALI REC-STN\"`    | 3         |\n",
    "| MAHANANDA REC-STN     | `'MAHANANDA REC-STN'`, `'MAHANANDA'`                                             | 2         |\n",
    "| GORAI REC-STN         | `'GORAI REC-STN'`, `'220kV GORAI REC-STN'`                                       | 2         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAROL REC-STN' 'KALANAGAR REC-STN' 'KURLA REC-STN'\n",
      " 'NIRLON B10 RECEIVING STATION' 'KOHINOOR RECEIVING STATION'\n",
      " 'OSHIWARA RECEIVING STATION' 'MAROL' 'MEGHAWADI REC-STN' 'MALAD REC-STN'\n",
      " 'ANDHERI REC-STN' 'VIKHROLI REC-STN' 'NESCO RECEIVING STATION'\n",
      " 'NIRLON REC-STN' 'HINDUSTAN UNILEVER REC-STN' 'BOMBILWADI REC-STN'\n",
      " 'K.I.E. REC-STN' \"TATA'S BORIVLI REC-STN\" 'MAHINDRA AND MAHINDRA REC-STN'\n",
      " 'MIRA REC-STN' 'TIMES OF INDIA REC-STN' '24TH ROAD REC-STN'\n",
      " 'MMRDA REC-STN' 'CHINCHAVLI REC-STN' 'PALM COURT'\n",
      " 'J. B. NAGAR RECEIVING STATION' 'M.I.D.C. REC-STN' 'AMBIVLI REC-STN'\n",
      " 'JUHU REC-STN' 'HINGWALA LANE REC-STN' 'KALPATARU LBS R/S'\n",
      " 'TILAK NAGAR REC-STN' 'HIRANANDANI REC-STN' 'VILE-PARLE REC-STN'\n",
      " 'HCC REC-STN' 'SEEPZ REC-STN' 'SAMBHAJI NAGAR REC-STN' 'NAHAR SHAKTI R/S'\n",
      " 'SAHAR PLAZA REC-STN' 'SAHAR PLAZA' 'NAHAR SHAKTI REC-STN'\n",
      " 'SHRADDHANAND ROAD REC-STN' 'RUNWAL REC-STN' 'SAMBHAJI NAGAR'\n",
      " 'GOKULDHAM REC-STN' 'RAHEJA I.T. PARK REC-STN' 'SARVODAY NAGAR REC-STN'\n",
      " 'MAHANANDA REC-STN' 'CHAKALA REC-STN' 'VIHAR RD. REC-STN'\n",
      " 'KALINA REC-STN' 'MAKERS REC-STN' 'RIL REC-STN' 'KADAMWADI REC-STN'\n",
      " 'POISAR REC-STN' 'HIRANANDANI HERITAGE R/S' 'DAHISAR REC-STN'\n",
      " 'DINDOSHI REC-STN' 'DINDOSHI VIA OMKAR REC STN' 'OMKAR RECEIVING STATION'\n",
      " 'LOKHANDWALA REC-STN' 'KANAKIA CCI REC-STN' 'KANAKIA CCI'\n",
      " 'SHIMPOLI REC-STN' 'KANDIVLI REC-STN' 'BORIVALI REC-STN'\n",
      " 'NATWAR PAREKH REC-STN' 'ACROPOLIS REC-STN' 'MHADA SAHAKAR NGR REC-STN'\n",
      " 'ANIK R/S' 'SHIVAJI NAGAR REC-STN' 'CHHEDA NAGAR REC-STN'\n",
      " '220kV CHEMBUR REC-STN' 'MHADA MANKHURD RECEIVING STATION'\n",
      " 'CHEMBUR REC-STN' 'MAHUL SRA REC-STN' 'ANIK REC-STN'\n",
      " 'SIDHARTH NAGAR RECEIVING STATION' 'MAHUL SRA' 'BANDRA TERMINUS'\n",
      " 'BANDRA TERMINUS REC-STN' 'SANTACRUZ REC-STN' 'CHUNABHATTI REC-STN'\n",
      " 'BANDRA REC-STN' 'KHAR REC-STN' 'PALI REC-STN' 'SHANTI STAR MIRA REC-STN'\n",
      " 'BHAYANDAR REC-STN' 'DAHISAR WEST REC-STN' 'DEVIDAS LANE REC-STN'\n",
      " 'BHAYANDAR WEST REC-STN' 'SADGURU REC-STN' 'DAHISAR CHECKNAKA REC-STN'\n",
      " 'VINAMRA REC-STN' 'RAVI MHADA REC-STN' 'VAZIRA REC-STN'\n",
      " 'JANKALYAN NAGAR RECEIVING STATION' 'CPWD MALWANI RECEIVING STATION'\n",
      " 'RNA ROYAL PARK REC-STN' 'GORAI REC-STN' 'SWAMI SAMARTH NAGAR REC-STN'\n",
      " 'CAMA REC-STN' 'KOHINOOR CITY REC-STN' 'GANESH NAGAR MHADA REC-STN'\n",
      " 'NETMAGIC DC-9 NO 1 BUS 1 DSS' 'GODREJ BKC REC-STN'\n",
      " 'MIAL T-2 DSS REC-STN' 'ESIC REC-STN' 'CHANDIVLI SRA REC-STN'\n",
      " 'SWAN MILL REC-STN' '1S-MH-MU-ZET-RSTN-NET2'\n",
      " 'NETMAGIC DC-9 NO 2 BUS 1 DSS' 'NETMAGIC DC-9 NO 1 RECEIVING STATIO'\n",
      " 'SARASWATI RD. REC-STN' 'MIND SPACE REC-STN' 'ERANGLE REC-STN'\n",
      " 'VERSOVA MCGM PUMPING R/S' 'PALM COURT REC-STN' 'JUHU NORTH REC-STN'\n",
      " 'BHAVANS RECEIVING STATION' 'ANDHERI' 'AMBIVLI' 'TAGORE NGR. REC-STN'\n",
      " 'KALPATARU LBS REC-STN' 'CHINCH BUNDER REC-STN' nan]\n"
     ]
    }
   ],
   "source": [
    "col = df['DESTINATION_SS'].unique()\n",
    "len(col)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31cb16",
   "metadata": {},
   "source": [
    "| **Standardized Station Name** | **Variants Found**                                                                |\n",
    "| ----------------------------- | --------------------------------------------------------------------------------- |\n",
    "| MAROL REC-STN                 | `'MAROL'`, `'MAROL REC-STN'`                                                      |\n",
    "| SAHAR PLAZA REC-STN           | `'SAHAR PLAZA'`, `'SAHAR PLAZA REC-STN'`                                          |\n",
    "| MAHANANDA REC-STN             | `'MAHANANDA'`, `'MAHANANDA REC-STN'`                                              |\n",
    "| CHEMBUR REC-STN               | `'CHEMBUR REC-STN'`, `'220kV CHEMBUR REC-STN'`                                    |\n",
    "| BORIVALI REC-STN              | `\"TATA'S BORIVLI REC-STN\"`, `'BORIVALI REC-STN'`                                  |\n",
    "| DAHISAR REC-STN               | `'DAHISAR REC-STN'`, `'DAHISAR WEST REC-STN'`, `'DAHISAR CHECKNAKA REC-STN'`      |\n",
    "| NIRLON REC-STN                | `'NIRLON REC-STN'`, `'NIRLON B10 RECEIVING STATION'`                              |\n",
    "| KANAKIA CCI REC-STN           | `'KANAKIA CCI'`, `'KANAKIA CCI REC-STN'`                                          |\n",
    "| BHAYANDAR REC-STN             | `'SHANTI STAR MIRA REC-STN'`, `'BHAYANDAR REC-STN'`, `'BHAYANDAR WEST REC-STN'`   |\n",
    "| SAMBHAJI NAGAR REC-STN        | `'SAMBHAJI NAGAR'`, `'SAMBHAJI NAGAR REC-STN'`                                    |\n",
    "| DINDOSHI REC-STN              | `'DINDOSHI REC-STN'`, `'OMKAR RECEIVING STATION'`, `'DINDOSHI VIA OMKAR REC STN'` |\n",
    "| NAHAR SHAKTI REC-STN          | `'NAHAR SHAKTI R/S'`, `'NAHAR SHAKTI REC-STN'`                                    |\n",
    "| JUHU REC-STN                  | `'JUHU REC-STN'`, `'JUHU NORTH REC-STN'`                                          |\n",
    "| ANDHERI REC-STN               | `'ANDHERI REC-STN'`, `'ANDHERI'`                                                  |\n",
    "| AMBIVLI REC-STN               | `'AMBIVLI REC-STN'`, `'AMBIVLI'`                                                  |\n",
    "| KALPATARU LBS REC-STN         | `'KALPATARU LBS R/S'`, `'KALPATARU LBS REC-STN'`                                  |\n",
    "| NETMAGIC DC-9 NO 1            | `'NETMAGIC DC-9 NO 1 BUS 1 DSS'`, `'NETMAGIC DC-9 NO 1 RECEIVING STATIO'`         |\n",
    "| PALM COURT REC-STN            | `'PALM COURT'`, `'PALM COURT REC-STN'`                                            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c364bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7115a2a3",
   "metadata": {},
   "source": [
    "ML ALGORITHM TO LEARN WEIGHT FROM OLD HALTH SCORE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741f11da",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/__init__.py:26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/compat/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     pa_version_under10p1,\n\u001b[1;32m     29\u001b[0m     pa_version_under11p0,\n\u001b[1;32m     30\u001b[0m     pa_version_under13p0,\n\u001b[1;32m     31\u001b[0m     pa_version_under14p0,\n\u001b[1;32m     32\u001b[0m     pa_version_under14p1,\n\u001b[1;32m     33\u001b[0m     pa_version_under16p0,\n\u001b[1;32m     34\u001b[0m     pa_version_under17p0,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m F\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/compat/pyarrow.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     _palv \u001b[38;5;241m=\u001b[39m Version(Version(pa\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version)\n\u001b[1;32m     11\u001b[0m     pa_version_under10p1 \u001b[38;5;241m=\u001b[39m _palv \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pyarrow/__init__.py:61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (BuildInfo, RuntimeInfo, set_timezone_db_path,\n\u001b[1;32m     63\u001b[0m                          MonthDayNano, VersionInfo, cpp_build_info,\n\u001b[1;32m     64\u001b[0m                          cpp_version, cpp_version_info, runtime_info,\n\u001b[1;32m     65\u001b[0m                          cpu_count, set_cpu_count, enable_signal_handlers,\n\u001b[1;32m     66\u001b[0m                          io_thread_count, set_io_thread_count)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow_versions\u001b[39m():\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pyarrow/types.pxi:2364\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/abc.py:105\u001b[0m, in \u001b[0;36mABCMeta.__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mABCMeta\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Metaclass for defining Abstract Base Classes (ABCs).\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Use this metaclass to create an ABC.  An ABC can be subclassed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    even via super()).\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(mcls, name, bases, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(mcls, name, bases, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    107\u001b[0m         _abc_init(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/SWNO_MASTER_COMBINED_FULL.csv\")  # ⬅ Replace with actual file name\n",
    "\n",
    "# Step 1: Feature Engineering\n",
    "now_year = datetime.now().year\n",
    "\n",
    "if 'DATECREATED' in df.columns:\n",
    "    years = pd.to_datetime(df['DATECREATED'], errors='coerce').dt.year\n",
    "    df['CABLE_AGE'] = now_year - years.fillna(now_year)\n",
    "\n",
    "# Current mean and std\n",
    "current_cols = [c for c in df.columns if c.startswith('I_Month_')]\n",
    "if current_cols:\n",
    "    currents = df[current_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    df['CURRENT_MEAN'] = currents.mean(axis=1)\n",
    "    df['CURRENT_STD'] = currents.std(axis=1)\n",
    "\n",
    "# PEAK, CYCLE, OVR\n",
    "for prefix, name in [('PEAK_Month_', 'PEAK'), ('CYCLE_Month_', 'CYCLE'), ('OVR_Month_', 'OVR')]:\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    if cols:\n",
    "        arr = df[cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        df[f'{name}_MEAN'] = arr.mean(axis=1)\n",
    "        df[f'{name}_STD'] = arr.std(axis=1)\n",
    "\n",
    "# Cable type risk\n",
    "if 'CABLETYPE' in df.columns:\n",
    "    df['CABLETYPE_RISK'] = df['CABLETYPE'].apply(\n",
    "        lambda t: 1 if 'PILC' in str(t).upper() else (0.2 if 'XLPE' in str(t).upper() else 0.5)\n",
    "    )\n",
    "\n",
    "# Material risk\n",
    "if 'CABLECONDUCTORMATERIAL' in df.columns:\n",
    "    df['MATERIAL_RISK'] = df['CABLECONDUCTORMATERIAL'].apply(\n",
    "        lambda m: 0.7 if 'AL' in str(m).upper() else (0.2 if 'CU' in str(m).upper() or 'COPPER' in str(m).upper() else 0.5)\n",
    "    )\n",
    "\n",
    "# FUSE count\n",
    "fuse_cols = [col for col in df.columns if col.startswith('FAULT_RELAY_FUSE')]\n",
    "if fuse_cols:\n",
    "    df['FUSE_COUNT'] = df[fuse_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1)\n",
    "\n",
    "# Step 2: Feature List\n",
    "features = [\n",
    "    'Num_Faults', 'CURRENT_MEAN', 'CURRENT_STD', 'CABLE_AGE',\n",
    "    'PEAK_STD', 'CYCLE_STD', 'OVR_MEAN', 'OVR_STD',\n",
    "    'FUSE_COUNT', 'CABLETYPE_RISK', 'MATERIAL_RISK'\n",
    "]\n",
    "\n",
    "# Step 3: Filter valid data\n",
    "df = df.dropna(subset=features)\n",
    "# Add this before training to generate Health_Score\n",
    "from datetime import datetime\n",
    "\n",
    "def compute_health_score(df):\n",
    "    weights = {\n",
    "        'Num_Faults': 0.15,\n",
    "        'CURRENT_MEAN': 0.05,\n",
    "        'CURRENT_STD': 0.05,\n",
    "        'CABLE_AGE': 0.15,\n",
    "        'PEAK_STD': 0.15,\n",
    "        'CYCLE_STD': 0.05,\n",
    "        'OVR_MEAN': 0.15,\n",
    "        'OVR_STD': 0.05,\n",
    "        'FUSE_COUNT': 0.02,\n",
    "        'CABLETYPE_RISK': 0.015,\n",
    "        'MATERIAL_RISK': 0.015\n",
    "    }\n",
    "\n",
    "    now_year = datetime.now().year\n",
    "    if 'DATECREATED' in df.columns:\n",
    "        years = pd.to_datetime(df['DATECREATED'], errors='coerce').dt.year\n",
    "        df['CABLE_AGE'] = now_year - years.fillna(now_year)\n",
    "\n",
    "    current_cols = [c for c in df.columns if c.startswith('I_Month_')]\n",
    "    if current_cols:\n",
    "        currents = df[current_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        df['CURRENT_MEAN'] = currents.mean(axis=1)\n",
    "        df['CURRENT_STD'] = currents.std(axis=1)\n",
    "\n",
    "    for prefix, name in [('PEAK_Month_', 'PEAK'), ('CYCLE_Month_', 'CYCLE'), ('OVR_Month_', 'OVR')]:\n",
    "        cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "        if cols:\n",
    "            arr = df[cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "            df[f'{name}_MEAN'] = arr.mean(axis=1)\n",
    "            df[f'{name}_STD'] = arr.std(axis=1)\n",
    "\n",
    "    if 'CABLETYPE' in df.columns:\n",
    "        df['CABLETYPE_RISK'] = df['CABLETYPE'].apply(lambda t: 1 if 'PILC' in str(t).upper() else (0.2 if 'XLPE' in str(t).upper() else 0.5))\n",
    "    if 'CABLECONDUCTORMATERIAL' in df.columns:\n",
    "        df['MATERIAL_RISK'] = df['CABLECONDUCTORMATERIAL'].apply(lambda m: 0.7 if 'AL' in str(m).upper() else (0.2 if 'CU' in str(m).upper() or 'COPPER' in str(m).upper() else 0.5))\n",
    "\n",
    "    fuse_cols = [col for col in df.columns if col.startswith('FAULT_RELAY_FUSE')]\n",
    "    if fuse_cols:\n",
    "        df['FUSE_COUNT'] = df[fuse_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1)\n",
    "\n",
    "    used = {k: v for k, v in weights.items() if k in df.columns}\n",
    "    total_weight = sum(used.values())\n",
    "    score = pd.Series(0, index=df.index, dtype=float)\n",
    "\n",
    "    for i in df.index:\n",
    "        contributions = {}\n",
    "        for k, w in used.items():\n",
    "            vals = pd.to_numeric(df[k], errors='coerce').fillna(0)\n",
    "            rng = vals.max() - vals.min()\n",
    "            normed = (vals[i] - vals.min()) / rng if rng else 0\n",
    "            contributions[k] = normed * (w / total_weight)\n",
    "        score[i] = sum(contributions.values())\n",
    "\n",
    "    df['Health_Score'] = (1 + 9 * (1 - score)).round().astype(int)\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "df = compute_health_score(df)\n",
    "\n",
    "# Step 4: Define Target Column\n",
    "if 'Health_Score' not in df.columns:\n",
    "    raise ValueError(\"Missing target column 'Health_Score'. Please compute it or replace with another target.\")\n",
    "\n",
    "X = df[features]\n",
    "y = df['Health_Score']  # Replace with another column like 'Fault_Prob' if needed\n",
    "\n",
    "# Step 5: Normalize and Train Model\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Step 6: Get Feature Importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Step 7: Normalize importances to sum to 1\n",
    "weight_dict = dict(zip(features, importances))\n",
    "total = sum(weight_dict.values())\n",
    "normalized_weights = {k: round(v / total, 4) for k, v in weight_dict.items()}\n",
    "\n",
    "# Step 8: Print Weights\n",
    "print(\"🔍 Learned Feature Weights Based on Data:\\n\")\n",
    "for feature, weight in normalized_weights.items():\n",
    "    print(f\"{feature:20} : {weight}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59bc1f",
   "metadata": {},
   "source": [
    "EM ALGORITHM BY ADVANCED LOSS FEEDBACK AND IMPROVE THE HEALTH SCORE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 01 | MSE: 11.9158\n",
      "Iteration 11 | MSE: 8.8455\n",
      "Iteration 21 | MSE: 7.0016\n",
      "Iteration 31 | MSE: 6.8128\n",
      "Iteration 41 | MSE: 6.8207\n",
      "Iteration 50 | MSE: 6.7942\n",
      "\n",
      "✅ Refined Feature Weights Learned via EM + Feedback:\n",
      "\n",
      "Num_Faults           : 0.0665\n",
      "CURRENT_MEAN         : 0.1027\n",
      "CURRENT_STD          : 0.0922\n",
      "CABLE_AGE            : 0.0392\n",
      "PEAK_STD             : 0.0475\n",
      "CYCLE_STD            : 0.0583\n",
      "OVR_MEAN             : 0.0543\n",
      "OVR_STD              : 0.0672\n",
      "FUSE_COUNT           : 0.0443\n",
      "CABLETYPE_RISK       : 0.0402\n",
      "MATERIAL_RISK        : 0.3875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def sigmoid(x, k=5):\n",
    "    return 1 / (1 + np.exp(-k * (x - 0.5)))\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load & Feature Engineering\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/SWNO_MASTER_COMBINED_FULL.csv\")\n",
    "\n",
    "now_year = pd.Timestamp.now().year\n",
    "if 'DATECREATED' in df.columns:\n",
    "    years = pd.to_datetime(df['DATECREATED'], errors='coerce').dt.year\n",
    "    df['CABLE_AGE'] = now_year - years.fillna(now_year)\n",
    "\n",
    "current_cols = [c for c in df.columns if c.startswith('I_Month_')]\n",
    "if current_cols:\n",
    "    currents = df[current_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    df['CURRENT_MEAN'] = currents.mean(axis=1)\n",
    "    df['CURRENT_STD'] = currents.std(axis=1)\n",
    "\n",
    "for prefix, name in [('PEAK_Month_', 'PEAK'), ('CYCLE_Month_', 'CYCLE'), ('OVR_Month_', 'OVR')]:\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    if cols:\n",
    "        arr = df[cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        df[f'{name}_MEAN'] = arr.mean(axis=1)\n",
    "        df[f'{name}_STD'] = arr.std(axis=1)\n",
    "\n",
    "if 'CABLETYPE' in df.columns:\n",
    "    df['CABLETYPE_RISK'] = df['CABLETYPE'].apply(lambda t: 1 if 'PILC' in str(t).upper() else (0.2 if 'XLPE' in str(t).upper() else 0.5))\n",
    "if 'CABLECONDUCTORMATERIAL' in df.columns:\n",
    "    df['MATERIAL_RISK'] = df['CABLECONDUCTORMATERIAL'].apply(lambda m: 0.7 if 'AL' in str(m).upper() else (0.2 if 'CU' in str(m).upper() else 0.5))\n",
    "\n",
    "fuse_cols = [col for col in df.columns if col.startswith('FAULT_RELAY_FUSE')]\n",
    "if fuse_cols:\n",
    "    df['FUSE_COUNT'] = df[fuse_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Select Valid Features\n",
    "# -------------------------------\n",
    "features = [\n",
    "    'Num_Faults', 'CURRENT_MEAN', 'CURRENT_STD', 'CABLE_AGE',\n",
    "    'PEAK_STD', 'CYCLE_STD', 'OVR_MEAN', 'OVR_STD',\n",
    "    'FUSE_COUNT', 'CABLETYPE_RISK', 'MATERIAL_RISK'\n",
    "]\n",
    "df = df.dropna(subset=features)\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(df[features]), columns=features)\n",
    "\n",
    "# Target\n",
    "if 'Health_Score' not in df.columns:\n",
    "    df['Health_Score'] = np.random.randint(1, 10, size=len(df))  # replace this with real scores\n",
    "y_true = df['Health_Score'].astype(float)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. EM-style Learning\n",
    "# -------------------------------\n",
    "weights = pd.Series(1 / len(features), index=features)\n",
    "n_iters = 50\n",
    "lr = 0.1\n",
    "\n",
    "for iter in range(n_iters):\n",
    "    # --- E-Step: Predict Health Score ---\n",
    "    weighted_sigmoid = (X.apply(sigmoid)).mul(weights).sum(axis=1)\n",
    "    predicted = 10 * (1 - weighted_sigmoid)\n",
    "    predicted = predicted.clip(1, 10)\n",
    "\n",
    "    # --- M-Step: Calculate Error ---\n",
    "    mse = mean_squared_error(y_true, predicted)\n",
    "    \n",
    "    # Compute gradient: smoothed sensitivity\n",
    "    gradient = {}\n",
    "    delta = 0.01\n",
    "    for f in features:\n",
    "        temp_weights = weights.copy()\n",
    "        temp_weights[f] += delta\n",
    "        temp_pred = 10 * (1 - (X.apply(sigmoid)).mul(temp_weights).sum(axis=1))\n",
    "        temp_mse = mean_squared_error(y_true, temp_pred)\n",
    "        gradient[f] = (temp_mse - mse) / delta\n",
    "\n",
    "    # Update weights with regularization (to avoid exploding weights)\n",
    "    for f in features:\n",
    "        weights[f] -= lr * gradient[f]\n",
    "\n",
    "    weights = weights.clip(lower=0)\n",
    "    weights /= weights.sum()  # normalize\n",
    "\n",
    "    if iter % 10 == 0 or iter == n_iters - 1:\n",
    "        print(f\"Iteration {iter+1:02d} | MSE: {mse:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Final Output\n",
    "# -------------------------------\n",
    "print(\"\\n Refined Feature Weights Learned via EM + Feedback:\\n\")\n",
    "for f, w in weights.round(4).items():\n",
    "    print(f\"{f:20} : {w}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f21d4d",
   "metadata": {},
   "source": [
    "ADD A NEW LABELE IS_FAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 01 | MSE: 48.7604\n",
      "Iteration 11 | MSE: 20.1903\n",
      "Iteration 21 | MSE: 20.1903\n",
      "Iteration 31 | MSE: 20.1903\n",
      "Iteration 41 | MSE: 20.1903\n",
      "Iteration 51 | MSE: 20.1903\n",
      "Iteration 61 | MSE: 20.1903\n",
      "Iteration 71 | MSE: 20.1903\n",
      "Iteration 81 | MSE: 20.1903\n",
      "Iteration 91 | MSE: 20.1903\n",
      "Iteration 101 | MSE: 20.1903\n",
      "Iteration 111 | MSE: 20.1903\n",
      "Iteration 121 | MSE: 20.1903\n",
      "Iteration 131 | MSE: 20.1903\n",
      "Iteration 141 | MSE: 20.1903\n",
      "Iteration 151 | MSE: 20.1903\n",
      "Iteration 161 | MSE: 20.1903\n",
      "Iteration 171 | MSE: 20.1903\n",
      "Iteration 181 | MSE: 20.1903\n",
      "Iteration 191 | MSE: 20.1903\n",
      "Iteration 201 | MSE: 20.1903\n",
      "Iteration 211 | MSE: 20.1903\n",
      "Iteration 221 | MSE: 20.1903\n",
      "Iteration 231 | MSE: 20.1903\n",
      "Iteration 241 | MSE: 20.1903\n",
      "Iteration 251 | MSE: 20.1903\n",
      "Iteration 261 | MSE: 20.1903\n",
      "Iteration 271 | MSE: 20.1903\n",
      "Iteration 281 | MSE: 20.1903\n",
      "Iteration 291 | MSE: 20.1903\n",
      "Iteration 301 | MSE: 20.1903\n",
      "Iteration 311 | MSE: 20.1903\n",
      "Iteration 321 | MSE: 20.1903\n",
      "Iteration 331 | MSE: 20.1903\n",
      "Iteration 341 | MSE: 20.1903\n",
      "Iteration 351 | MSE: 20.1903\n",
      "Iteration 361 | MSE: 20.1903\n",
      "Iteration 371 | MSE: 20.1903\n",
      "Iteration 381 | MSE: 20.1903\n",
      "Iteration 391 | MSE: 20.1903\n",
      "Iteration 401 | MSE: 20.1903\n",
      "Iteration 411 | MSE: 20.1903\n",
      "Iteration 421 | MSE: 20.1903\n",
      "Iteration 431 | MSE: 20.1903\n",
      "Iteration 441 | MSE: 20.1903\n",
      "Iteration 451 | MSE: 20.1903\n",
      "Iteration 461 | MSE: 20.1903\n",
      "Iteration 471 | MSE: 20.1903\n",
      "Iteration 481 | MSE: 20.1903\n",
      "Iteration 491 | MSE: 20.1903\n",
      "Iteration 500 | MSE: 20.1903\n",
      "\n",
      "✅ Final Weights (EM + Real Target + Penalized Updates):\n",
      "\n",
      "Num_Faults           : 0.0402\n",
      "CURRENT_MEAN         : 0.1368\n",
      "CURRENT_STD          : 0.0269\n",
      "CABLE_AGE            : 0.2185\n",
      "PEAK_STD             : 0.0284\n",
      "CYCLE_STD            : 0.1075\n",
      "OVR_MEAN             : 0.0274\n",
      "OVR_STD              : 0.0329\n",
      "FUSE_COUNT           : 0.024\n",
      "CABLETYPE_RISK       : 0.0391\n",
      "MATERIAL_RISK        : 0.3182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def sigmoid(x, k=5):\n",
    "    return 1 / (1 + np.exp(-k * (x - 0.5)))\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/SWNO_MASTER_COMBINED_FULL.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "now_year = pd.Timestamp.now().year\n",
    "if 'DATECREATED' in df.columns:\n",
    "    years = pd.to_datetime(df['DATECREATED'], errors='coerce').dt.year\n",
    "    df['CABLE_AGE'] = now_year - years.fillna(now_year)\n",
    "\n",
    "current_cols = [c for c in df.columns if c.startswith('I_Month_')]\n",
    "if current_cols:\n",
    "    currents = df[current_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    df['CURRENT_MEAN'] = currents.mean(axis=1)\n",
    "    df['CURRENT_STD'] = currents.std(axis=1)\n",
    "\n",
    "for prefix, name in [('PEAK_Month_', 'PEAK'), ('CYCLE_Month_', 'CYCLE'), ('OVR_Month_', 'OVR')]:\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    if cols:\n",
    "        arr = df[cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        df[f'{name}_MEAN'] = arr.mean(axis=1)\n",
    "        df[f'{name}_STD'] = arr.std(axis=1)\n",
    "\n",
    "if 'CABLETYPE' in df.columns:\n",
    "    df['CABLETYPE_RISK'] = df['CABLETYPE'].apply(lambda t: 1 if 'PILC' in str(t).upper() else (0.2 if 'XLPE' in str(t).upper() else 0.5))\n",
    "\n",
    "if 'CABLECONDUCTORMATERIAL' in df.columns:\n",
    "    df['MATERIAL_RISK'] = df['CABLECONDUCTORMATERIAL'].apply(lambda m: 0.7 if 'AL' in str(m).upper() else (0.2 if 'CU' in str(m).upper() else 0.5))\n",
    "\n",
    "fuse_cols = [col for col in df.columns if col.startswith('FAULT_RELAY_FUSE')]\n",
    "if fuse_cols:\n",
    "    df['FUSE_COUNT'] = df[fuse_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1)\n",
    "\n",
    "# Features & target\n",
    "features = [\n",
    "    'Num_Faults', 'CURRENT_MEAN', 'CURRENT_STD', 'CABLE_AGE',\n",
    "    'PEAK_STD', 'CYCLE_STD', 'OVR_MEAN', 'OVR_STD',\n",
    "    'FUSE_COUNT', 'CABLETYPE_RISK', 'MATERIAL_RISK'\n",
    "]\n",
    "df = df.dropna(subset=features)\n",
    "\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(df[features]), columns=features)\n",
    "\n",
    "# REAL TARGET — use actual number of faults\n",
    "# Option A: Use actual count (recommended for regression)\n",
    "y_true = df['Num_Faults'].clip(upper=10).astype(float)\n",
    "\n",
    "# Option B: Use binary target (for classification)\n",
    "# y_true = (df['Num_Faults'] > 0).astype(float)\n",
    "\n",
    "# Feature penalty boosts (domain knowledge)\n",
    "penalty_boosts = {\n",
    "    'Num_Faults': 2.0,\n",
    "    'CABLE_AGE': 1.5,\n",
    "    'MATERIAL_RISK': 1.2,\n",
    "    'CURRENT_MEAN': 1.0,\n",
    "    'CURRENT_STD': 1.0,\n",
    "    'PEAK_STD': 1.0,\n",
    "    'CYCLE_STD': 1.0,\n",
    "    'OVR_MEAN': 1.0,\n",
    "    'OVR_STD': 1.0,\n",
    "    'FUSE_COUNT': 1.0,\n",
    "    'CABLETYPE_RISK': 1.0\n",
    "}\n",
    "\n",
    "# EM-style training\n",
    "weights = pd.Series(1 / len(features), index=features)\n",
    "n_iters = 500\n",
    "lr = 0.1\n",
    "\n",
    "for iter in range(n_iters):\n",
    "    weighted_sigmoid = (X.apply(sigmoid)).mul(weights).sum(axis=1)\n",
    "    predicted = 10 * (1 - weighted_sigmoid)\n",
    "    predicted = predicted.clip(0, 10)\n",
    "\n",
    "    mse = mean_squared_error(y_true, predicted)\n",
    "\n",
    "    gradient = {}\n",
    "    delta = 0.01\n",
    "    for f in features:\n",
    "        temp_weights = weights.copy()\n",
    "        temp_weights[f] += delta\n",
    "        temp_pred = 10 * (1 - (X.apply(sigmoid)).mul(temp_weights).sum(axis=1))\n",
    "        temp_mse = mean_squared_error(y_true, temp_pred)\n",
    "        grad = (temp_mse - mse) / delta\n",
    "\n",
    "        # Apply feature-specific penalty\n",
    "        gradient[f] = grad * penalty_boosts.get(f, 1.0)\n",
    "\n",
    "    for f in features:\n",
    "        weights[f] -= lr * gradient[f]\n",
    "\n",
    "    weights = weights.clip(lower=0)\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    if iter % 10 == 0 or iter == n_iters - 1:\n",
    "        print(f\"Iteration {iter+1:02d} | MSE: {mse:.4f}\")\n",
    "\n",
    "# Final output\n",
    "print(\"\\nFinal Weights (EM + Real Target + Penalized Updates):\\n\")\n",
    "for f, w in weights.round(4).items():\n",
    "    print(f\"{f:20} : {w}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 001 | MSE: 0.4876\n",
      "Iteration 011 | MSE: 0.3405\n",
      "Iteration 021 | MSE: 0.2280\n",
      "Iteration 031 | MSE: 0.1424\n",
      "Iteration 041 | MSE: 0.1050\n",
      "Iteration 051 | MSE: 0.0971\n",
      "Iteration 061 | MSE: 0.0903\n",
      "Iteration 071 | MSE: 0.0838\n",
      "Iteration 081 | MSE: 0.0777\n",
      "Iteration 091 | MSE: 0.0719\n",
      "Iteration 100 | MSE: 0.0671\n",
      "\n",
      "✅ Final Weights (EM + Real Target + Penalized Updates):\n",
      "\n",
      "Num_Faults           : 0.0001\n",
      "CURRENT_MEAN         : 0.1439\n",
      "CURRENT_STD          : 0.0001\n",
      "CABLE_AGE            : 0.1667\n",
      "PEAK_STD             : 0.0001\n",
      "CYCLE_STD            : 0.0531\n",
      "OVR_MEAN             : 0.0001\n",
      "OVR_STD              : 0.0001\n",
      "FUSE_COUNT           : 0.0001\n",
      "CABLETYPE_RISK       : 0.0001\n",
      "MATERIAL_RISK        : 0.6356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sigmoid function for health degradation scaling\n",
    "def sigmoid(x, k=5):\n",
    "    return 1 / (1 + np.exp(-k * (x - 0.5)))\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"/media/sagark24/New Volume/MERGE CDIS/IPYNB_FILE/DATA_GENERATION/SWNO_MASTER_COMBINED_FULL.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "now_year = pd.Timestamp.now().year\n",
    "if 'DATECREATED' in df.columns:\n",
    "    years = pd.to_datetime(df['DATECREATED'], errors='coerce').dt.year\n",
    "    df['CABLE_AGE'] = now_year - years.fillna(now_year)\n",
    "\n",
    "current_cols = [c for c in df.columns if c.startswith('I_Month_')]\n",
    "if current_cols:\n",
    "    current = df[current_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    df['CURRENT_MEAN'] = current.mean(axis=1)\n",
    "    df['CURRENT_STD'] = current.std(axis=1)\n",
    "\n",
    "for prefix, name in [('PEAK_Month_', 'PEAK'), ('CYCLE_Month_', 'CYCLE'), ('OVR_Month_', 'OVR')]:\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    if cols:\n",
    "        arr = df[cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        df[f'{name}_MEAN'] = arr.mean(axis=1)\n",
    "        df[f'{name}_STD'] = arr.std(axis=1)\n",
    "\n",
    "if 'CABLETYPE' in df.columns:\n",
    "    df['CABLETYPE_RISK'] = df['CABLETYPE'].apply(lambda t: 1 if 'PILC' in str(t).upper() else (0.2 if 'XLPE' in str(t).upper() else 0.5))\n",
    "\n",
    "if 'CABLECONDUCTORMATERIAL' in df.columns:\n",
    "    df['MATERIAL_RISK'] = df['CABLECONDUCTORMATERIAL'].apply(lambda m: 0.7 if 'AL' in str(m).upper() else (0.2 if 'CU' in str(m).upper() else 0.5))\n",
    "\n",
    "fuse_cols = [c for c in df.columns if c.startswith('FAULT_RELAY_FUSE')]\n",
    "if fuse_cols:\n",
    "    df['FUSE_COUNT'] = df[fuse_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1)\n",
    "\n",
    "# Select relevant features\n",
    "features = [\n",
    "    'Num_Faults', 'CURRENT_MEAN', 'CURRENT_STD', 'CABLE_AGE',\n",
    "    'PEAK_STD', 'CYCLE_STD', 'OVR_MEAN', 'OVR_STD',\n",
    "    'FUSE_COUNT', 'CABLETYPE_RISK', 'MATERIAL_RISK'\n",
    "]\n",
    "\n",
    "# Drop incomplete rows\n",
    "df = df.dropna(subset=features)\n",
    "\n",
    "# Normalize feature values\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(df[features]), columns=features)\n",
    "\n",
    "# Ground truth: fault count (or clip to max 10)\n",
    "y_true = df['Num_Faults'].clip(upper=10).astype(float)\n",
    "\n",
    "# Domain-based penalty scaling per feature\n",
    "penalty_boosts = {\n",
    "    'Num_Faults': 2.0,\n",
    "    'CABLE_AGE': 1.5,\n",
    "    'MATERIAL_RISK': 1.2,\n",
    "    'CURRENT_MEAN': 1.0,\n",
    "    'CURRENT_STD': 1.0,\n",
    "    'PEAK_STD': 1.0,\n",
    "    'CYCLE_STD': 1.0,\n",
    "    'OVR_MEAN': 1.0,\n",
    "    'OVR_STD': 1.0,\n",
    "    'FUSE_COUNT': 1.0,\n",
    "    'CABLETYPE_RISK': 1.0\n",
    "}\n",
    "\n",
    "# Initialize weights uniformly\n",
    "weights = pd.Series(1 / len(features), index=features)\n",
    "\n",
    "# Normalize y_true to [0, 1] for stability\n",
    "y_true_scaled = y_true / 10.0\n",
    "\n",
    "# EM-style optimization with regularization\n",
    "n_iters = 100\n",
    "lr = 0.01\n",
    "l2_penalty = 0.01  # L2 regularization strength\n",
    "\n",
    "for iter in range(n_iters):\n",
    "    sigmoid_vals = X.apply(sigmoid)\n",
    "    predicted = (1 - sigmoid_vals.mul(weights).sum(axis=1)).clip(0, 1)\n",
    "    mse = mean_squared_error(y_true_scaled, predicted)\n",
    "\n",
    "    gradient = {}\n",
    "    delta = 1e-4\n",
    "    for f in features:\n",
    "        temp_weights = weights.copy()\n",
    "        temp_weights[f] += delta\n",
    "        temp_weights /= temp_weights.sum()\n",
    "\n",
    "        temp_pred = (1 - X.apply(sigmoid).mul(temp_weights).sum(axis=1)).clip(0, 1)\n",
    "        temp_mse = mean_squared_error(y_true_scaled, temp_pred)\n",
    "        grad = (temp_mse - mse) / delta\n",
    "\n",
    "        # Add L2 regularization\n",
    "        reg_term = 2 * weights[f] * l2_penalty\n",
    "        gradient[f] = (grad + reg_term) * penalty_boosts.get(f, 1.0)\n",
    "\n",
    "    # Update and normalize\n",
    "    for f in features:\n",
    "        weights[f] -= lr * gradient[f]\n",
    "\n",
    "    weights = weights.clip(lower=1e-4)  # prevent collapse\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    if iter % 10 == 0 or iter == n_iters - 1:\n",
    "        print(f\"Iteration {iter+1:03d} | MSE: {mse:.4f}\")\n",
    "\n",
    "\n",
    "# Print learned weights\n",
    "print(\"\\n Final Weights (EM + Real Target + Penalized Updates):\\n\")\n",
    "for f, w in weights.round(4).items():\n",
    "    print(f\"{f:20} : {w}\")\n",
    "\n",
    "# Final Health Score using learned weights\n",
    "df['Advanced_Health_Score'] = (10 * (1 - X.apply(sigmoid).mul(weights).sum(axis=1))).clip(0, 10).round()\n",
    "\n",
    "# Save if needed\n",
    "# df.to_csv(\"final_health_score_output.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
